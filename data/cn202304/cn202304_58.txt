大规模语言模型的跨云联合训练关键技术 潘囿丞  等 热点专题
中兴通讯技术
2023  年 8 月    第 29 卷第  4 期   Aug . 2023    Vol . 29  No. 414的西班牙语 （Es）到英语 （En）的机器翻译任务 ，并采
用ABNet 跨云架构基于预训练语言模型进行微调训练 。在该
实验中 ，我们使用多语言预训练模型 ERNIE-M-base-cased
作为编码端 ，使用英文预训练模型 BERT-Base 作为解码端 ，
并将它们分别部署在两个配备了 8张NVIDIA V 100 GPU 显卡
的云集群上 。
实验结果显示 ，完全重新训练的 Transformer-Base 模
型[14]的双语评估替换 （BLEU ）值[15]为39.60，在本地微调训
练 的 ABNet-Local 模 型 为 43.19，采 用 跨 云 微 调 训 练 的
ABNet-Cloud 模型为 41.92。实验结果表明 ，采用基于预训练
模型微调的翻译模型性能优于仅使用训练数据重新训练的
Transformer-Base 模型 。相对于仅在本地集群训练的 ABNet-
Local 模型 ，跨云微调的 ABNet-Cloud 模型的 BLEU 值降低了
1.27个，这是由于压缩通信导致了模型精度损失 。然而 ，相
对于 Transformer-Base 模型 ，ABNet-Cloud 仍然提高了 2.32
个BLEU 值。这表明在跨云环境中 ，基于预训练语言模型进
行微调训练可以复用预训练模型的知识 ，从而提高最终翻译
模型的精度 。
为了研究压缩通信策略对模型训练的影响 ，我们对不同
压缩通信策略下的模型训练速度和最终模型精度进行了对
比。其中 ，前向计算数据传输采用 FP16半精度及其与不同
压缩率的 SVD 分解的组合 ，反向传播采用固定的 INT8量化
压缩 。实验结 果如表 2所示，压缩率越高 ，模型训练速度越
快。在FP16(SVD(0.2))+INT 8的压缩策略下 ，模型训练单步
消耗时间仅为不压缩训练的 19%。然而 ，该策略下模型精度
损失了 4.19个BLEU 值。在所验证的压缩策略中 ，FP16(SVD
(0.6))+INT 8策略下得到的模型精度最佳 （达到 41.92） ，单步
训练时间仅为不压缩的 32%，训练速度提升了 3倍以上 。
2.2.2 针对自然语言理解任务的微调
自然语言理解包括文本分类 、
文本蕴含 、阅读理解等任务 。通常
人们采用基于编码器类型的预训练
模型进行微调训练 。为了在跨云环
境下微调这类模型 ，可以采用低秩
结构的思想对通信数据进行压缩[16]。
具体的做法如下 ：
1）对 于 模 型 中 的 每 一 个
Transformer 块，假设其输入和输出
矩阵的维度为 RRb×d，即在跨云训练
时，通信数据的维度也为 RRb×d。其
中，b表示 batch_size ，d表示模型的维度参数 。
2）对于其中一个 Transformer 块的线性层 ，可以进行奇
异值分解来降低通信数据的维度 。具体做法是 ：将该线性层
的权重矩阵 WW∈RRm×d进行奇异值分解 ，选取前 r个奇异值 ，
得到 3个矩阵 uu、ss和vv，维度分别为 RRm×r、RRr×r和RRr×d；然
后，使用 3个连续的线性层来替代原始的线性层 ，这3个线
性层的权重分别为 U、S和V，如图 8所示。
3）将用于跨云通信的模型拆分点设置在 S和V层之间 ，
并移除该 Transformer 块的直接连接分支 。这样 ，通信数据的
维度会变成 RRb×r，即原有数据的 r/d倍。
根据上述的压缩方案 ，以BERT-Base 为基础模型 ，在
GLUE 数据集[17]和SQuAD 数据集[18]上进行跨云微调训练 ，并
分析该算法在不同层索引上对训练精度的影响 。将上述算法
中的 r设置为 8，实验结果 如图 9所示 。其中 ，横轴表示拆分
的层级索引 ，纵轴表示准 确率 。需要说明的是 ，由于各个数
据集表现出的规律一致 ，这里仅以 SST- 2和QNLI 数据集为
代表 。
由图 9可知 ，r值较小且拆分位置处于模型的底层会导
致训练精度显著下降 。但是 ，当拆分位置位于模型的高层
时，r值的大小对训练精度没有影响 。在实验中 ，我们选择▼表2 不同压缩通信方法性能对比
压缩方法
ABNet-Local
FP16+INT 8
FP16（SVD（0.8） ）+INT 8
FP16（SVD（0.6） ）+INT 8
FP16（SVD（0.4） ）+INT 8
FP16（SVD（0.2） ）+INT 8BLEU
43.19
38.82
41.15
41.92
39.56
39.00训练速度 （s/步）
4.42
1.60
1.50
1.42
0.94
0.86
BLEU ：双语评估替换
FP16：半精度SVD：奇异值分解
INT8：8比特量化
图8 低秩分解过程Transformer 层
Transformer 层
Transformer 层
Transformer 层归一化层
残差连接 &归一化层
自注意力层前馈层 -1vv
ss
uu残差连接 &归一化层
前馈层 -2
前馈层 -1
残差连接 &归一化层
自注意力层……L层 ➡
54