大规模语言模型的跨云联合训练关键技术 潘囿丞  等 热点专题
中兴通讯技术
2023  年 8 月    第 29 卷第  4 期   Aug . 2023    Vol . 29  No. 4不仅可以进一步减少数据传输量 ，还可以避免数据泄露 。
为了支持多源数据多方协同训练 ，该架构需要使用多个
生成器来共同训练判别器 。不同的生成器对应不同的训练数
据和不同的预训练模型 ，例如 ：可以让每个生成器负责一个
语种的生成 ，多个生成器共同支持多语言判别器的训练 ，这
样可以提高训练效率 ，增强判别器的泛化能力 。
在模型训练过程中 ，生成器和判别器之间只有单向的字
符标识序列传输 ，数据量小 ，受网络带宽瓶颈影响较小 。为
了提高集群资源的利用率和训练速度 ，本文中我们采用了数
据并行的方式在生成器集群和判别器集群内部分别进行训
练。为了验证该框架在异构算力环境下的模型训练能力 ，我
们将生成器部署在 GPU 算力集群 ，将判别器部署在 NPU 算
力集群 。该框架的跨云集群部署及并行计算方 式如图 4所
示。这种部署和计算方式可以提高训练效率 ，优化资源利
用率 。
为了测试跨云模型预训练的效果 ，实验中我们利用包含
116种语言的单语数据和 15种语言的平行语料数据 ，进行基
于生成器 -判别器架构的跨云大模型训练 。使用多语言预训练语言模型 ERNIE-M-Base 来初始化生成器 ，使用 ERNIE-
M-Large 来初始化判别器 ，训练得到的判别器 ERNIE-M-
Extra 则作为最终的多语言大模型 。为了测试 ERNIE-M-
Extra 模型的多语言能力 ，本文中我们首先使用英语数据进
行微调 ，然后在 15种语言的跨语言推理任务上进行了测试 。
测试结 果如表 1所示。
由表 1可知 ，ERNIE-M-Extra 模型在 15种语言的跨语言
推 理 任 务 中 表 现 出 最 优 的 平 均 成 绩 ，相 比 于 基 础 模 型
ERNIE-M-Large ，其精度提高了 0.2。
为了测试模型训练过程的吞吐率 ，我们进行了在云集群
内和跨云集群环境下的测试 。实验结果显示 ，跨云训练的吞
吐率达到了单云集群训练的 85%。在GPU 算力集群和 NPU
算力集群环境下 ，针对异构环境下硬件加速效果进行了实
验，并对比了由 8卡NPU 算力增加到 64卡的模型训练速度 。
实验结果表明 ，增加算力卡后训练速度提高了 4.34倍。
为了验证模型在跨云集群训练中的有效性 ，本文对比了
单云环境和跨云环境下模型训练的损失曲 线，如图 5所示 。
可以看出 ，跨云集群训练可以保持训练过程的持续收敛 。
综上所述 ，采用生成器 -判别器
架构进行多语言大模型训练 ，可以
在跨云环境下保持较高的吞吐率 ，
确保训练过程持续收敛 。此外 ，增
加算力资源可以有效提高训练速度 。
2.2 大规模语言模型的跨云微调
方法
微调是指在预训练大模型的基
础上 ，为了特定的任务进行有针对
性的模型训练 。本文中我们将分别
介绍基于编码器 -解码器架构的自然
▼表1 跨云模型预训练最终模型精度对比
模型
XLM[7]
Unicoder[8]
XLM-R[9]
INFOXLM[10]
ERNIE-M[11]
XLM-RLARGE[9]
INFOXLMLARGE[10]
VECOLARGE[12]
ERNIE-MLARGE[11]
ERNIE-M-ExtraEn
85.0
85.1
85.8
86.4
85.5
89.1
89.7
88.2
89.3
89.4Fr
78.7
79.0
79.7
80.6
80.1
84.1
84.5
79.2
85.1
85.1Es
78.9
79.4
80.7
80.8
81.2
85.1
85.5
83.1
85.7
86.0De
77.8
77.8
78.7
78.9
79.2
83.9
84.1
82.9
84.4
84.5El
76.6
77.2
77.5
77.8
79.1
82.9
83.4
81.2
83.7
84.4Bg
77.4
77.2
79.6
78.9
80.4
84.0
84.2
84.2
84.5
84.6Ru
75.3
76.3
78.1
77.6
78.1
81.2
81.3
82.8
82.0
81.8Tr
72.5
72.8
74.2
75.6
76.8
79.6
80.9
76.2
81.2
81.7Ar
73.1
73.5
73.8
74.0
76.3
79.8
80.4
80.3
81.2
81.8Vi
76.1
76.4
76.5
77.0
78.3
80.8
80.8
74.3
81.9
81.9Th
73.2
73.6
74.6
73.7
75.8
78.1
78.9
77.0
79.2
79.3Zh
76.5
76.2
76.7
76.7
77.4
80.2
80.9
78.4
81.0
81.2Hi
69.6
69.4
72.4
72.0
72.9
76.9
77.9
71.3
78.6
79.1Sw
68.4
69.7
66.5
66.4
69.5
73.9
74.8
80.4
76.2
76.3Ur
67.3
66.7
68.3
67.1
68.8
73.8
73.7
79.1
75.4
75.7平均
75.1
75.4
76.2
76.2
77.3
80.9
81.4
79.9
82.0
82.2图4 跨云预训练集群算力互联及并行计算方式GPU：图形处理器       NPU ：神经网络处理器前向计算标签云集群 A
生成器
数据并行GPU 0
GPU 7GPU 0
GPU 7云集群 B
判别器
数据并行
GPU 0
数据并行
GPU 7NPU 0
NPU 7
NPU 56
NPU 63数据并行
GPU 0
52