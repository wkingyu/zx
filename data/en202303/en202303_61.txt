ZTE COMMUNICATIONS
September  2023  Vol.21 No.3CHENG Lei , QIN Shuang , FENG Gang Learning -Based Admission Control for Low -Earth -Orbit Satellite Communication Networks    Research Papers
where Cov is the covariance matrix with diagonal σ2. Based on 
the policy , an action vector will be generated and the system 
will transit to a new state after a decision period TΔ.
2) Critic : The Critic is used to approximate the state -value 
function Vπ(s). Traditional RL uses Q -value tables to record 
state values , which will face the problem of dimensional explo ‐
sion under the scenario of large state space . To cope with this 
problem , a neural network parameterized by θ is utilized to ap ‐
proximate the state -value function Vθ(s). In the critic process , 
Vθ(s) will be updated by updating parameters θ.
To evaluate the gap between the actual value and the ap ‐
proximated value of the state -value function in the state s, the 
definition of TD -error is given as follows :
δt=Vπ(st+1)-Vθ(st), (22)
where Vπ(st+1)=rt+1+γVθ(st+1) according to the bootstrap ‐
ping method in the RL framework . To guide the updating of 
parameters and improve the performance , the objective of the 
critic process is designed to minimize the TD -error δt and can 
be re -expressed as :
min 12(δt)2 . (23)
θ is updated by the gradient descent method as follows :
θnew=θold-αcritic|δt|∇θoldVθold(st), (24)
where αcritic is the learning rate of the Critic .
3) Actor -Critic : The Actor updates the policy based on the 
state -value estimated by the Critic , while the Critic updates the 
state -value function according to the actions selected by the Ac ‐
tor and the state transitions generated by interactions with the 
environment . Besides , the performance of the Actor can be im ‐
proved by replacing δt with an advantage function . Then the pa ‐
rameter update process in Actor can be rewritten as :
∇ξU(πξ)=∇ξlogπξ(at|st) δt, (25)
ξnew=ξold+αactor∇ξoldlogπξold(at|st)δt. (26)
In summary , the proposed AC -DCRS is summarized as follows :
Algorithm 1. AC-DCRS
Input : N, M, T, TΔ, σ, αactor, αcritic, λ, γ.
Output : Optimal dynamic adjustment policy πξ.
Initialize : t=0, n=1, ξ=ξ0, θ=θ0, a=a0, s=s0, Φ(s0);
Repeat :
1. Action selection :
Input Φ(st) into the Actor network to get μ(st) and 
select action a, i.e., adjust the threshold once .
    2. According to the threshold adjusted by action , con‐
trol incoming calls , while (t≤nTΔ):1) if a service call arrives , judge its service type and 
priority
2) determine whether the call access is successful 
by the corresponding threshold :
a) if c is less than the corresponding threshold , 
the call is admitted successfully and can be allo ‐
cated a channel resource c←c+1;
b) else the call is blocked .
3) record the result of this call
4)  t←t+1.
3. State transition and reward feedback :
1) obtain the access result in this TΔ
2) transition into the new state st+1, get a reward rt+1
3) update state feature vector Φ(st+1)
4) calculate the state -value function Vθ(st+1), Vθ(st).
4. Update policy :
1) Critic network calculates and outputs TD -error δt=
rt+1+γVθ(st+1)-Vθ(st)
2) update Critic network parameters θ←θ-
αcritic|δt|∇θVθ(st)
3) update Actor network parameters
 ξ←ξ+αactor∇ξlogπξ(at|st)δt .
5. n←n+1,  st←st+1.
Until : t≥T.
3.3 Complexity Analysis
In this subsection , we analyze the computing and space 
complexity of AC -DCRS and compare it with three baseline al ‐
gorithms , i.e., FCR , handover priority fixed channel reserva ‐
tion strategy (HPFCR ), and DCR .
In FCR and HPFCR , the thresholds are fixed . In HPFCR , 
the handover calls are given higher priority , and the thresh ‐
olds for new calls are set to the same value . After the initial 
setting , the thresholds of DCR will dynamically change accord ‐
ing to the proportion of the number of calls of various services 
after the decision period TΔ has passed . Its normalized thresh ‐
old can be expressed as :
KDCR=c′+1-c′
n[n1, n1+n′1,…, n1+…+n′s],(27)
where c′ represents the normalized number of shared chan ‐
nels, which can be used by all calls , n represents the total 
number of calls arrived , and ni and n′i represent the number of 
new calls and handover calls of the i-th service respectively . 
As both FCR and HPFCR use a fixed threshold , the comput ‐
ing complexity is O(1)and the space complexity is O(s). On 
the other hand , DCR will dynamically change the threshold ac ‐
cording to Eq . (27), and thus the computing complexity and 
space complexity are both equal to O(s).
In our AC -DCRS , the neural networks are introduced to fit 
the policy function and the threshold is obtained according to 
the output feature vector . Specifically , we use a fully -
59