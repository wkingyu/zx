智能算力核心基础系统软件的现状与展望 郑纬民  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2本文中 ，我们将对这些智能算力核心系统软件做出介
绍，并通过回顾全球发展现状 ，探讨当前中国算力平台上系
统软件所面临的机遇和挑战 。
1 编程开发软件
大模型的编程开发软件主要有编程语言 、编程框架 。大
模型的开发既需要适应模型的快速迭代 ，又需要利用各类硬
件加速器来运行训练并推理所需的巨量计算 。为满足这一需
求，用于大模型的编程语言形成了模型开发语言与计算开发
语言的分工 ，后者由前者通过深度学习编程框架来调用 。目
前主流的模型开发语言为 Python 语言 ，在其上实现的现代深
度学习编程框架支持自动微分 、Python 绑定和直观的调试方
法等功能 ，为算法开发者提供了良好的易用性 。计算开发语
言则由于各异的硬件体系结构呈现出百花齐放的状态 。
1.1 编程语言
为了适应各异的硬件体系结构 ，许多硬件厂商需要使用
各自不同的计算开发语言来编写其硬件加速器上的程序 。目
前，国际上用于大模型的主流硬件是英伟达公司的图形处理
器（GPU） ，主要使用 CUDA[1]作为其编程语言 。另外 ，第三
方编程语言 Triton[2]也被广泛用于编写英伟达 GPU 上的大模
型相关计算 。中国具有代表性的硬件公司也采用了不同的编
程语言 ，例如寒武纪的 BANGC[3]、华为的 AscendC[4]、壁刃
的BIRENSUPA[5]、摩尔线程的 MUSA[6]。这些编程语言中使
用了不同的抽象来描述并行 、访存与计算 ，可面向不同硬件
进行针对性优化 ，但同时这也使不同硬件平台上的软件环境
互不兼容 。这给开发者灵活利用不同的硬件资源带来了
挑战 。
为了应对这一挑战 ，OpenCL[7]、SYCL[8]等编程语言致力
于以更广泛的抽象来表达多种不同硬件加速器上的程序 。更
进一步地 ，Mojo[9]不仅计划统一多种硬件加速器 ，还力求统
一模型开发语言与计算开发语言 ，以一套语言完成大模型的
全流程开发 。但是 ，统一的语言仍需不同编译器针对具体硬
件来逐一实现 ，例如英特尔公司的 oneAPI DPC++[10]就是针
对英特尔及英伟达 GPU 的编译器实现的 。下文中我们也将
介绍编译器的发展现状 。
1.2 编程框架
大模型的复杂度使得直接使用编程语言来开发模型变得
十分困难 ，因此编程框架成为深度学习算法开发者与计算系
统交互的界面 ，对深度学习训练和推理任务的计算性能产生
了很大的影响 。Caffe[11]是最早用于深度学习训练任务的框架之一 ，具有
自动微分和 GPU 支持的功能 。它提供了一个带有 Python 和
MATLAB 绑定的 C++机器学习库 ，使用内置的应用程序编程
接口 （API）来定义和训练模型 。为了更好地表达各种模型
结构和操作 ，Google 开发了 TensorFlow[12]框架 。TensorFlow 将
神经网络模型表示为数据流有向无环图 （DAG）的框架 。
TensorFlow 已应用于许多领域 ，包括自然语言处理 、计算机
视觉 、基于物理的 AI应用等 。然而 ，在TensorFlow 中，用户
需要先使用一段代码来描述模型的结构 ，再使用一段代码来
描述训练的过程 。这一较为抽象的工作模式给开发和调试工
作带来了额外的困难 。PyTorch[13]是由 Meta 开发的神经网络
训练和推理框架 。相比 TensorFlow ，PyTorch 基于动态计算
图，在代码实现上更灵活 ，调试更容易 。作为最用户友好的
框架之一 ，PyTorch 在工业界和学术界都被广泛使用 。然而 ，
其动态特性使得许多优化 （例如内核融合和计算图转换 ）难
以实现 。
百度 PaddlePaddle[14]和华为 MindSpore[15]等新一代框架结
合了 TensorFlow 和PyTorch 的特性 ，通过同时支持静态和动
态模式的方法 ，既保证了易用性 ，又可以基于编译技术对计
算过程进行更多的优化 ，甚至可以通过自动张量切分等技术
实现自动的多卡并行训练 。
然而 ，目前国际上围绕 PyTorch 平台已形成了丰富的软
件生态 。例如 Megatron-LM[16]、DeepSpeed[17]、HuggingFace[18]
等围绕 Transformer 模型的上层应用软件均基于 PyTorch 来实
现。这些基于 PyTorch 生态的软件为模型开发和使用者带来
了极大的便利 ，从而进一步鼓励了开发者为这个生态系统开
发更多的软件 。而Paddle 等国产编程框架的用户基数较小 ，
在软件生态上与 PyTorch 还有着较大的差距 。为迎头赶上 ，
厂商需持续带动用户 ，积极建设中国平台上的开源社区 。
2 并行加速软件
近年来 ，随着大模型规模的扩展 ，多机多卡协同分布式
计算成为大模型的计算范式 。并行计算系统及其通信库支撑
了大模型的高性能分布式计算 。针对大模型训练和推理的计
算特征 ，并行计算系统中的多种并行策略被提出 ，以充分利
用计算资源 ；通信库则提供了跨机跨卡的通信能力 ，并力求
高效实现这些并行策略所需的复杂通信模式 。
2.1 并行计算系统
并行计算系统满足了大模型训练和推理对存储和计算的
高需求 。大模型的参数量往往超过单个加速卡的内存容量 ；
其训练所需的计算量也远超单卡的计算能力 。国际上主流的
03