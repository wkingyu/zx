大模型训练技术综述 田海东  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2系统使用更少的训练步骤来实现相同或更好的准确性 。如何
定量和定性地理解数据集本身就是一个研究挑战 。文献 [11]
提出了后缀数组子串处理和相似度匹配算法两种可扩展的技
术，以检测和删除重复的训练数据 。
RefindedWeb[12]对数据集的处理方式更为激进 ，采用了
Bloomfilter 和Simhash 近似去重 ，这导致删除率远高于其他
方法 。RefindedWeb 同时证明 ，只用网页数据并通过严格的
过滤 、去重和脚本处理等手段 ，同样可以获取大模型所需的
训练语料 。
文献 [13]则引入数据年龄 、质量及毒性危害程度 、领域
组成等更多维度的量化评价指标 ，分析对大模型训练的影
响，为模型训练数据准备提供了指导方法 。
2）建立数据生产体系
从零开始预训练大模型需要高昂的成本 。开源的大模型
通常不附带开源的数据集 。因此 ，如何高效体系化地收集处
理数据显得尤为重要 。Ziya2[14]构建了完整的数据生产体系 ，
包括预处理数据 、自动评分 、基于规则的过滤 、消除重复内
容和评估数据等子任务 。RefinedWeb[12]则提出宏数据优化
（MDR ）处理数据的思想 ，侧重于去重和过滤 。
3）隐私和安全
一般来说 ，模型泄露数据的主要原因是过拟合 。此时模
型会记住数据集中的数据 。在大规模数据上进行训练也会存
留“记忆 ” 。文献 [15]基于此在 GPT2上进行攻击验证 ，认为
在数据准备 、增加噪声 、微调各阶段中都需要有防止数据泄
露的措施 。删除数据集敏感数据是其中一种方法 。知识遗忘
作为一种替代方法 ，也可以用来降低语言模型的隐私风险[16]。
文献 [15]在执行遗忘时不仅能提供更强的隐私保障 ，还能保
障模型性能不下降 ，并发现一次性忘记许多样本会导致显著
的模型性能下降 ，而顺序遗忘数据可以缓解这种情况 。
2 数据加载
大模型训练需要大量数据 、资源和时间 ，它涉及服务器
中所有资源的综合利用 ，如图 1所示 。数据加载是指 ，从存储器中读取数据 ，根据不同的模型训练要求 ，对读取的数据
设置不同的预处理规则 。存储介质 、缓存大小 、用于获取和
预处理数据的 CPU 线程数量等因素 ，都会影响到数据加载
的性能 。
理想情况下 ，数据加载部分需要稳定地将预处理后的数
据发送给 GPU ，以便 GPU 能够持续进行数据计算 ，充分发
挥计算能力 。但在实际工作中 ，主流的训练框架如 PyTorch 、
TensorFlow 等，在进行数据加载和数据预处理时都存在性能
瓶颈 。我们将这些瓶颈统称为数据停滞 。
目前有多种解决方案都在研究如何解决模型训练过程中
的数据停滞问题 ，主要包括以下几种 ：
1） 缓存策略
很多训练平台 （如 PyTorch 等）提供了 DataLoader ，支
持提前将数据从存储器读取到内存中 ，并且通常依赖操作系
统的页面缓存技术来缓存重复访问的原始训练数据 。通过实
验数据分析 ，数据集的访问模式与操作系统缓存替换策略并
不一致 。操作系统的页面缓存机制在提升训练效率方面并不
明显 。
分析大模型训练有其独特的数据访问模式 。每个训练周
期内系统会以随机方式遍历一次数据集中的所有数据样本 。
而基于样本重要性 、动态打包和多任务处理机制等高速缓存
置换算法[17]的研究 ，则能够有效减少数据停滞时间 ，提升训
练速度 。
2） 分布式数据加载
分布式技术可以将训练任务分配到多个计算节点上进行
并行计算 ，以提高训练效率 。分布式训练将数据分成多个批
次，然后在不同的存储节点上并行加载数据 ，以减少数据加
载等待时间 。对于分布式训练过程中存在的同一份数据在多
个节点上重复缓存的情况[18]，如果缓存之间缺乏协调 ，分布
式训练就容易受到存储接口的限制 。此时 ，可通过设置数据
流策略将存储接口操作与计算操作并行化处理 ，来进一步提
高训练效率 。
另外 ，当参数量很大时 ，数据通信量也可能会成为模型
▲图1 数据加载基本流程CPU：中央处理器      GPU ：图形处理器存储器 缓存 数据预取 CPU 预处理 GPU 处理数据加载
22