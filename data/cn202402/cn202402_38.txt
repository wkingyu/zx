通信网络与大模型的融合与协同 任天骐  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2度处理 。在服务部署阶段 ，逻辑 AI工作流将根据服务质量
需求映射到相应的物理资源 。在融合通信和计算 （C&C）资
源管理层面 ，我们不仅需要考虑控制面的无缝连接和用户平
面中的信息传输可靠性 ，还需要在计算平面中有效地协调异
构计算资源 。此外 ，该架构还引入新的协议栈以传输 AI生
成的消息 ，并实时更新和分发模型 ，同时考虑引入新的标识
符来为实时 AI工作流优先分配网络资源 。
总体而言 ，网络大模型实现了 C&C 资源的深度融合 ，
并通过个性化的云边大模型耦合更新机制促进了云边协同以
提高服务质量 。此外 ，通过在边缘处理私有数据 ，在云端处
理大数据的分割机制 ，达成了计算效率和数据安全的最优
平衡 。
3 问题与挑战
目前 ，将AI算法融入通信系统已经有众多应用场景 ，
如AI赋能物理层 、AI赋能高层 、AI赋能应用层等 。此前 ，
研究人员在这些应用场景做出了许多有益的尝试[40]，包括但
不限于基于 AI的信道估计及反馈[41-42]、基于 AI的多输入多
输出 （MIMO ）检测[43-44]、基于 AI的资源和功率分配[45]和基
于AI的传输层拥塞控制技术[46]等。这些研究都证明 ，与传
统通信模型相比 ，基于 AI/机器学习 （ML）的通信模型可以
获得更出色的性能 。目前的研究大多采用传统的 AI算法或
神经网络结构 ，但根据标度率的发现以及大模型在众多领域
展示出的卓越性能 ，我们有理由相信 ，将大模型应用于这些
任务中 ，将会获得更大的增益 。然而网络大模型领域的研究
依然面临着一系列基础性问题的挑战 。这些挑战主要涉及大
模型本身的设计类问题和网络设计如何支撑大模型应用类问
题[34]，主要如下 ：
1）模型协同 ：在不同规模和部署位置的模型之间实现
有效的数据和参数协同是一个主要挑战 。此外 ，不同任务类
型对模型推理协同的需求也有所不同 。针对跨域任务 ，L0
全网通用大模型需要协同多个 L1网络专业大模型进行处理 ，
并提供通用知识 ；而针对单域任务 ，L1网络专业大模型需
要和多个 L2网络小模型进行协同处理 ，并提供专业知识 。
总的来说 ，实现网络内不同规模模型的协同进化 ，以及明确
各自的职责 ，是解决这一挑战的关键策略 。
2）网络架构设计 ：引入 NetGPT 优化网络服务需要考虑
如何利用 NetGPT 的自然语言理解能力为应用程序生成专有
的网络服务 ，并处理模型更新导致的计算负担 。此外 ，考虑
到当前网络的基于字符串的接口协议可能被基于模型间的协
作接口取代 ，为了保证网络性能的实时性 、稳定性和可靠
性，需要把 NetGPT 深度融入 6G网络架构 ，推动网元的智能化 。
3）分布式学习与部署 ：在分布式网络中 ，考虑到节点
计算资源和存储能力的差异 ，模型需要分布式拆分和自适应
调整 。在模型学习算法层面 ，现有的模型并行和数据并行方
式存在局限性 ，因此还需要我们深入探索分布式训练方法 。
此外 ，分布式节点间的通信瓶颈是制约模型性能的关键因
素，这就需要从算法和网络设计两方面同时入手 ，进行模型
压缩 ，如剪枝和量化等 ，在网络内设计高效的节点间通信机
制。此外 ，数据隐私与数据异质性 、以及如何降低通信开
销，也是需要关注的问题 。
4）全生命周期管控和编排 ：在生命周期管控方面 ，不
仅要选择适当的拆分策略 ，还要设计高效的更新和维护策略
以应对计算开销和时间成本的显著增加 。同时 ，考虑到
NetGPT 的知识产权保护 ，还需要建立平衡的协同管理机制 。
在编排方面 ，需要对计算任务和网络资源进行合理的识别 、
编排和反馈 ，以提高系统性能和资源利用率 ，实现面向动态
需求的 NetGPT 闭环控制 。
4 结束语
大模型作为当前最热门的研究热点 ，毫无疑问将成为
AI与通信融合的关键组成部分 ，在提高网络中 AI的通用性
和多任务处理能力等方面发挥重要作用 。本文中 ，我们首先
从大模型的架构 、标度率和涌现能力以及 LLM 的训练微调
与对齐 3个方面回顾了大模型的理论与技术 ，之后探讨了
LLM 和生成式 AI在通信网络中的应用及其带来的双向增益 。
接下来 ，强调了 AI与通信网络的双向协同 ，包括 AI构建网
络和网络赋能 AI的概念 ，以及构建网络大模型 NetGPT 的实
践。网络大模型作为一种内生智能的新型网络架构展现出巨
大潜力 ，但要成功地部署网络大模型仍然存在一定的挑战 。
我们期待在该领域能有更多的前瞻性研究工作 ，为通信网络
与大模型的融合与协同带来创新和突破 。
致谢
感谢浙江大学陈宇轩和鲁芝琳在本文撰写过程中给予的
帮助和支持 。
参考文献
[1] VASWANI A , SHAZEER N , PARMAR N , et al . Attention is all you 
need [C]//Proceedings of the 31st International Conference on 
Neural Information Processing Systems . ACM , 2017 : 6000 –
6010 . DOI: 10.5555 /3295222 .3295349
[2] DEFLIN J , CHANG M W , LEE K , et al . Bert : pre-training of deep 
34