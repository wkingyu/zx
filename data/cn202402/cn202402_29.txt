大模型训练技术综述 田海东  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2迭代中根据样本决定一部分专家用于计算 ，并引入可训练的
门机制保证计算能力的优化 。Gshard[48]首次将 MoE 应用到
Transformer 上，将 间 隔 的 前 馈 神 经 网 络 （FFN）替 换 成
MoE。Switch Transformers[49]是在 T5模型上应用 MoE 设计的 ，
它简化了 MoE 的路由算法 ，具有门机制 ，即每次只推选一
个专家 。
在后续的研究中 ，微软的 Deepspeed-MoE[50]提出了一种
端到端的 MoE 训练和推理解决方案 ，有效减少了 MoE 模型
的大小 。Faster-MoE[51]提升了 MoE 模型分布式训练效率 ，与
大模型优化策略 （ZeRO 、Gshard 等）相比获得了显著的性
能加速 。
3） 自动并行
自动并行的目标是 ：用户给定一个模型和所使用的机器
资源后 ，系统能够自动地帮用户选择一个较好或者最优的并
行策略来实现高效执行 。可以说 ，自动并行是分布式并行的
终极目标 ，它能够减少或避免工程师手动设置分布式并行策
略。自动并行分为半自动和全自动两种模式 。其中 ，半自动
模式是指用户自己指定张量的切分方式 ，如Gshard[48]；全自
动模型是指由框架自适应选择切分方式 ，如Flexflow[52]等提
到的全自动并行切分方案 。
目前许多训练框架如 PyTorch 、TensorFlow 等实现了自
动并行 。Alpa[53]通过自动搜索 intra-op 的调度和 inter-op 的切
分方式 ，几乎兼顾了所有的并行策略 ，是自动并行的集大
成者 。
4.3 训练网络
大模型训练集群的各个计算节点之间通过网络进行互
联。网络性能直接决定节点间的通信效率 ，进而影响整个训
练集群的吞吐和性能 。随着模型规模的持续增大 ，大模型训
练网络面临着多种挑战 ：大规模扩展 、高通量和低延迟等 ，
除了需要带宽增强等基础技术的支撑[54]，还需从互联协议 、
网络拓扑 、在网计算等多个方面进行优化 。
1） 互联协议
训练网络互联技术通常分为两类 ：总线互联协议 （包
括：NVLink 、CXL 等）和 网 络 互 联 协 议 （包 括 ：RoCE 、
Infiniband 等） 。其中 ，前者用于计算芯片之间短距离 、小规
模的互联 ，而后者则用于计算节点之间长距离 、大规模的数
据通信 。随着总线和网络技术的发展 ，这两类技术已出现逐
渐融合的趋势 。例如 ，英伟达的 NVLink 4.0已经可以支持
256个GPU 的互联 ，CXL 在其最新的规范中也明确将支持机
架间的互联 。
2） 网络拓扑大模型训练对网络拓扑的扩展性 、可靠性和成本等都提
出了更高要求 。在高性能计算的发展中 ，Torus 无疑占据了
重要的位置 。相比于 Torus 结构 ，胖树网络路由算法更容易
实现 ，网络性能相对更出色 。但是胖树网络在扩展至更大规
模时需增加网络层数 ，从而导致链路数随之指数增长 ，这会
大大增加网络成本 。Dragonfly 由J. JIM 等在 2008 年提出[55]。
它的特点是网络直径小 、成本较低 ，在高性能计算方面有着
显著优势 。然而 ，面对整体网络节点的增多 ，Dragonfly 等网
络结构依然面临网络连线复杂 、网络设计成本高 、所需全局
光纤数多等挑战 。
除了上述拓扑结构 ，MIT和META 的rail-only[56]等还提
出了定制化拓扑结构 。这些拓扑结构专门针对大模型的通信
需求进行设计 ，目的是在提升性能的同时显著降低成本 。
3） 在网计算
在网计算通过网络交换侧和端侧设备的协同 ，利用网络
内部的硬件计算引擎 ，在网络通信过程中实现复杂操作的卸
载。基于树状聚合的机制 ，在网计算可以同时支持多个集合
操作 。以典型的 AllReduce 算子为例 ，传统的通信交互复杂
度为 O(logN)（N代表网络节点规模 ） ，启动在网计算功能后 ，
其交互复杂度变为 O(C)（C代表网络层级 ） ，大大简化了计
算节点间的通信交互过程 ，提升了计算效率 。
在训练网络中最知名的在网计算技术是英伟达的可扩展
分层聚合和归约协议 （SHARP ）[57]。Intel 提出的 switchML[58]
系统在其 Tofino 专用芯片的可编程交换机上 ，实现了 All‐
Reduce 操作 ，充分利用了交换机的编程能力 。
5 训练状态保存
随着参数规模达到千亿级 ，大模型训练时长会达到数十
天，训练过程也可能因各种软硬件故障而中断 。这就需要定
期保存模型训练的中间状态 ，包括 GPU 内存中的模型参数
和优化器状态 。发生故障时 ，将最近的检查点载入到 GPU
内存中 ，可以实现快速的故障恢复 ，系统此时只会丢失很短
时间内的计算结果 。然而 ，检查点操作过程中序列化 、压
缩、文件 IO的低效所引起的检查点停滞问题 ，也会阻塞训
练任务 ，浪费 GPU 计算资源 。因此 ，我们需要对检查点操
作进行优化 。主要优化方法如下 ：
1） 异步处理
GPU 与CPU 处理进行异步设计时 ，GPU 主要完成前向
传播 、后向传播 ，CPU 完成参数更新和检查点 。微软 Fiddle
团队在 CheckFreq[59]中使用动态建模分析 ，将CPU 处理的检
查点快照和持久化进行后台异步处理 。DeepFreeze[60]设计了
VELOC 框架用于实现序列化和压缩异步 。Gemini[61]给出的交
25