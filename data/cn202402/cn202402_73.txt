大模型知识管理系统 周 扬   等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2噪声 ，同时保持语义不丢失 ，进而为 LLM 提供更有效的上
下文信息 。常见的上下文压缩方法有内容摘要 、关键词提
取、LongLLMLingua[13]等。其中 ，LongLLMLingua 通过使用
对齐并训练好的小模型来检测移除上下文中不重要的 token ，
并将其转换为人类难以理解但 LLM 易于理解的形式 ，有效
提升了系统性能 。LongLLMLingua 的核心思想是将长输入分
两步处理 ：首先使用一个小型编码器模型 （通常是 BERT 等
双向编码器 ）将长输入编码为一个较短的向量表示 ，然后将
编码后的向量连同查询一起输入到一个 LLM 中（LLM 解码
器能够识别小型编码器编码后的信息 ） ，生成最终的输出 。
2.2.3.2 重排
在检索后处理阶段 ，为确保最相关且最有价值的检索结
果能够优先被用作回答查询的上下文输入 ，我们引入了重新
排序 （Reranking ）机制 。重排操作通过对检索阶段获得的
检索结果相关性评分进行再次调整 ，或采用更精细的排序算
法，从而实现检索结果的重新排列 。重排的关键在于设计高
效的打分模型 。常见的做法是引入交叉编码器 。对于给定查
询，交叉编码器将所有检索结果与之进行编码打分 ，然后按
得分递减排列 ，得分最高者即为最相关检索结果 。
为进一步提升重排性能 ，我们采用了经过训练的专门用
于重排的模型 ，其中 Cohere 公司的 Cohere 重排模型和智源的
bge-rerank[14]模型因具有代表性而被广泛使用 。本文中 ，我
们选用了 bge-rerank 作为重排器 ，搭配 bge-embedding 模型
进行文档嵌入 ，取得了良好效果 。重排环节的优化有助于提
高上下文的相关性和质量 ，从而为最终答案生成提供更为可
靠的语义支撑 。
2.3 答案生成技术
答案生成技术是指 ，依赖 LLM 本身的推理能力 ，结合
系统提供的上下文信息进行最终的答案生成 。目前 ，根据开
源情况 ，主流的 LLM 可以分为以 ChatGPT 为首的闭源模型和
以LLaMA 、Qwen 为首的开源模型两类 。在闭源大模型中 ，OpenAI 的ChatGPT- 4常常在各大评
测排行榜中名列前茅 ，而近期出现的 Claude 3也显示出了强
大的性能 。然而 ，尽管这些模型性能强劲 ，但由于它们是闭
源模型 ，只提供 API调用接口 ，费用昂贵 ，不适用于企业知
识库中需要频繁调用的场景 。此外 ，企业知识管理系统通常
涉及大量的企业内部知识 ，这对闭源商业模型的隐私保护提
出较高要求 。
本文所提知识管理系统方案采用了开源大模型 。在开源
大模型中 ，比较有名的包括清华大学的 ChatGLM 、阿里的
Qwen 以及 Meta 的LLaMA ，具体的参数规模和说明如表 1所
示。可以看出 ，ChatGLM- 6B受限于参数规模 ，相较于 14B
的模型性能略有不足 ，而LLaMA 模型本身只支持英文 ，即
使引入了中文补丁 ，在中文语境下 ，Qwen 模型性能更胜一
筹。综合考虑 ，我们在方案中选择了 Qwen- 14B模型 。
3 测评框架
为全面评估基于 RAG 架构的知识管理系统的性能表现 ，
我们需要一个科学全面的测评框架 。由S. ES等于 2023 年9
月提出的检索增强生成评估 （RAGAs ）[15]开源评估框架在业
界取得了良好的反响 。RAGAs 能够快速对 RAG 系统进行综
合评估 ，所需的输入包括 ：用户提出的查询问题 （Ques ‐
tion） 、RAG 系统生成的答案 （Answer ） 、检索到的与问题相
关的上下文文档 （Contexts ） ， 以及人工标注的参考答案
（Ground Truths )。
在获得上述输入信息后 ，RAGAs 基于以下 4个评估指标
对RAG 系统效果进行量化评分 ：
1）Faithfulness ，衡量生成答案与上下文是否保持一致 ，
反映了系统回答的可信赖性 。
2）Answer Relevancy ，评估生成答案与参考答案的语义
相关度 ，考察答案的准确性 。
3）Context Relevancy ，测量检索上下文与问题的关联程
度，体现上下文选择的恰当性 。
4）Context Recall ，计算系统检索到的相关上下文数量
▼表1 开源大模型参数规模和说明
模型名称
ChatGLM- 6B[7]
LLaMA- 7B[6]
LLaMA- 13B
Qwen- 7B[2]
Qwen- 14B参数大小 /亿
62
70
130
70
140MMLU
36.90
35.10
46.94
56.70
66.30CEval
38.90
27.10
/
59.60
72.10AGIEval
/
23.90
33.90
/
/推理显存 /GB
6
6
10
8
13
MMLU ：大规模多任务语言理解
69