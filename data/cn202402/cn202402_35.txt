通信网络与大模型的融合与协同 任天骐  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2地处理输入序列和输出序列之间的关系 ，适合需要理解输入
内容并生成相关响应的任务 ，如机器翻译 、生成式问答等 ，
但模型复杂度较高 ，训练时间和计算资源消耗较大 。
1.2 标度率和涌现能力
大模型的标度率是 OpenAI 在2020 年提出的概念[5]，是
AI模型训练过程中的一个重要的经验性发现 。在传统的小
模型中 ，其性能往往会随着训练次数的增加而趋于稳定 ，甚
至出现过拟合而导致性能下降 。大模型的标度率则揭示了一
个不同的现象 ：随着模型规模 、数据集大小以及训练计算量
的扩增 ，模型性能够获得持续提升 。具体而言 ，当不受其他
两个因素制约时 ，模型性能与每个单独的因素呈幂律关系 。
进一步的研究揭示[6]，当前的 LLM 实际上训练不足 ，而为了
实现最佳性能 ，模型规模和训练数据集大小应以大致相同的
速度扩增 。此外 ，除了数据集大小 ，数据质量也被认为是影
响模型性能的关键因素 。
标度率提出后 ，可以预见 ：随着模型参数量的增加 ，模
型在大部分任务中表现出的性能较为稳定 。而随着模型规模
的持续扩大 ，研究者发现[5]，对于特定的任务和模型来说 ，
在模型规模小于某个阈值之前 ，模型基本不具备任务解决能
力；但当模型规模大到一定程度时 ，模型性能显著提高 。这
被称为大模型的涌现能力 。
1.3 大语言模型的预训练 、微调与对齐
在大语言模型的预训练阶段 ，自监督学习发挥着核心的
作用 。该方法使模型能够在无需人工标注的数据集上学习并
理解语言的丰富特征 。自监督学习通过构建任务 ，如掩码语言模型 （MLM ）或自回归预测 ，使模型能够从大规模未标
注文本中抽取和学习复杂的语言结构和语义信息 。这种自监
督机制的广泛应用源于其赋予模型从大量的文本数据中学习
到通用语言表示的能力 ，这为模型后续进行特定任务的微调
奠定了坚实基础 。
预训练完成后 ，LLM 可以获得处理各种任务的通用能
力。为了将 LLM 适配到特定领域的任务 ，需要对 LLM 进行
微调 。LLM 的微调 ，通常采用监督学习的技术路线 。由于使
用的训练数据通常包含标签或特定任务的指导信息 ，监督学
习能使已经预训练过的模型针对具体的应用进行优化 ，提高
了特定任务上的表现 。近期 ，指令微调作为一种先进的微调
策略 ，允许模型通过理解并执行明确的任务指令来调整其行
为，进一步增强了模型对不同任务的适应能力和灵活性 。
预训练和微调的策略反映了一种互补性 ：前者通过自监
督学习为模型提供广泛的语言理解能力 ，而后者则确保模型
在前者的基础上针对特定任务实现优化 。这种互补性策略极
大地提升了模型在多种自然语言处理任务中的泛化能力 。
LLM 预训练使用了语言建模的目标 ，但却没有考虑到人
类的价值观或偏好 ，可能产生有害的 、误导性的或有偏见的
表达 ，因此需要一些对齐技术来使 LLM 的行为符合人类期
望。为 此 ，InstructGPT[25]利 用 基 于 人 类 反 馈 的 强 化 学 习
（RLHF ）技术[26]，通过学习奖励模型使 LLM 适配人类反馈 ，
并将人类纳入训练的循环中来得到对齐良好的 LLM[27]。
2 通信网络大模型的研究与发展
6G对网络架构提出了 “万物智联 ，数字孪生 ”的总体
愿景 ，强调智慧内生是 6G网络应当具备的一大特征[15]。这
图2 大型语言模型发展时间线……
…………
……
GPT
BERT
transformerALBERT
T5
GPT- 2
2017 —2018 2019 2020 2021 2022 2023
RoBERTa/
BART
XLNetBlender
DeBERTaTuring-
NLG
MT5
GPT- 3Pangu
ERNIE 3.0CPM- 2PaLM/
UL2/
FlanT 5/
Flan-PaLM
Chinchilla
Sparrow
BLOONERNIE 3.0
Titan
PaLM- 2/
Bard
GPT- 4/
Toolformer
T0Anthropic
OPT/Galatica
Instruct GPT/
ChatGPTChatGLM
LLaMAERNIE Bot年份
31