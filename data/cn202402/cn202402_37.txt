通信网络与大模型的融合与协同 任天骐  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 22.2 构建网络大模型的实践
在《网 络 大 模 型 的 十 大 问 题 》[34]中，网 络 大 模 型
（NetGPT ）被定义为无线网络中部署的大模型 ，其架构如图
5所示 。要实现通信网络与大模型的融合与协同 ，本质上是
要构建好网络大模型 。
在构建网络大模型的实践方面 ，WANG Y . C.[35]等调研了
如何利用边缘云计算范式构建大规模 GenAI 系统 。边缘云计
算是指计算和存储资源靠近数据源或终端设备 ，将计算功能
从传统的云数据中心推向网络边缘 。边缘云计算利用了云服
务器中强大的计算资源以及边缘服务器中高效的数据管理和
通信 。相比于云计算和多址边缘计算 ，边缘云计算在满足计
算要求和低延迟要求上展现出优势 ，同时具有良好的可扩展
性和数据安全性 。
然而 ，将计算功能推向网络边缘意味着 ，在边缘端模型
需要从云端进行计算卸载 ，且边缘和云端
将缺乏一定的关联性 。为了缓解这个问题 ，
CHEN Y .等[36]提出了一种云边协同的部署方
案，通过在云端与边缘端部署不同规模的
模型协同作业来实现目的 。在此架构中 ，
边缘端部署的 LLM 是轻量级的 ，专门优化
以适应边缘计算的资源限制 ，并能够利用
位置相关信息增强个性化服务 ，以满足区
域特定的需求 。相对而言 ，云端的设备由
于其更强大的计算能力和更大的存储空间 ，
部署了完整版本的 LLM ，负责处理更复杂
的全局任务 。图6中给出了 LLM 卸载微调和
LLM 协同的两种部署方案 。
在云边协同的架构中 ，边缘节点上的
LLM 负责收集并预处理来自本地区域的请
求，包括将简单请求扩展为含有丰富区域
特征的完整请求 ，并执行请求的去重整合 。
这些处理过的请求随后被发送到云端的
LLM ，后者利用其强大的计算能力生成高质
量、个性化的回答 。此过程不仅展现了通
信网络在赋能 AI方面的作用 ，还能通过边
缘与云端 LLM 的高效协作 ，提升 AI生成内
容的质量和个性化程度 ；而AI对通信网络
的增益则体现在通过边缘节点的 LLM 实现
请求的有效预处理和减少冗余传输 ，这能
够降低通信成本并优化网络时延 。
在云端和边缘端部署 LLM 都需要基于
预训练的 LLM 向通信任务进行迁移 。CHEN Y.等[36]在工作中选择并部署了 LLaMA- 7B模型和 GPT- 2-
base 模型 ，并对部署的 LLM 进行微调来适应任务需求 。在云
端部署的 LLaMA- 7B模型 ，无法直接生成响应式文本 ，因此
选择基于低秩适应 （LoRA ）的技术[37]，使用 Standford Al ‐
paca 数据集[38]进行参数高效的微调 。在边缘端部署的 GPT-
2-base 模型 ，需要附加基于位置的信息来扩展提示 ，以实现
个性化 ，因此选择 self-instruct 方法[39]，使用手动编写的位置
相关提示与 OpenAI 的TextDavinci- 003模型进行交互 ，来生
成有效的文本样本作为 “综合提示 ” 。
云边协同部署网络大模型的工作流程主要集中于协调边
缘和云端的一系列网络功能 ，并优化数据处理和分析的过
程。当用户请求生成特定内容时 ，该架构通过先进的逻辑
AI工作流来解析和编排服务 ，根据用户需求和网络状况的
动态变化 ，选择是在边缘端进行初步处理还是在云端执行深
图6 网络大模型部署方案[36]LLM：大语言模型
图5 网络大模型 NetGPT 的3层架构[34]L2
场景应用
L1
通信大模型
L0
基础大模型L0全网通用大模型L1空口大模型 L1核心网大模型 L1运维大模型L2端口
物理层L2数据
链路层L2
感知L2网
络节能L2拥
塞控制L2网
络切片L2网
络规划L2网
络优化L2网络
服务与
编排
云端 云端
协同 卸载&微调
边缘 边缘 边缘 边缘边缘云端
计算面
用户面
控制面
终端
（1）LLM 卸载微调 （2）LLM 协同
33