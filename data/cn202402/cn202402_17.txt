大语言模型算法演进综述 朱炫鹏  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2它们也会降低模型的计算效率 。Softmax 的计算公式为 ：
m=max(X)， yi=exi-m
∑j=0L-1exj-m
， （7）
其中 ，X表示输入向量 ，L表示输入向量长度 。从公式 （7）
可以看出 ，Softmax 计算会带来这些挑战 ：计算过程多次完
整访问向量 X，这导致数据长距离共享 ；每次计算一行向
量，这和通常矩阵运算访问数据的方式不一致 ，这会导致算
子融合困难 ；算术强度低 ，访存需求大 ，序列较长时需要反
复从片外内存读取数据 ，这降低了效率[19]。
LayerNorm 层包含激活的均值 、方差统计计算 ，也需要
多次访问向量 X，进行非线性计算 。这会造成计算效率的降
低，和Softmax 存在的问题类似 。
3.2 大语言模型推理效率提升方法
大语言模型推理效率的评价指标有 ：首token 生成延时 、
每秒生成 token 数、每token 消耗的芯片毫秒数[20]。提升推理
效率的思路主要有 3条：
• 增加计算硬件 ：进行分布式推理 ，将模型拆分到多个
GPU 上，提升推理速度 ，减小推理延时 ；• 减小计算量 ：删除模型中不必要的计算 ；
• 减小访存量 ：减少对外部存储器的访问 ，充分利用缓
存；降低数据精度 ，减小数据大小 。
3.2.1 分布式推理
当大语言模型计算量 、参数量超过单个 GPU 能力时 ，
就必须做分布式训练[21]和分布式推理 。分布式推理使用的两
种典型并行方式为 ：Tensor 并行和 Pipeline 并行 ，一般节点
内采用 Tensor 并行[22-24]，节点间采用 Pipeline 并行[23]。
Tensor 并行将每个 Transformer 层的计算量 、存储量平均
分布到多个 GPU 上，能有效降低推理延时 ，但会增加 GPU
间数据交互的负担 。因此选择 Tensor 并行度时 ，需要对比并
行计算收益和通信负担 ，综合评估效率指标 。
Pipeline 并行将模型的各个 Transformer 层分配到不同的
节点 ，每个节点负责不同的层 。在推理时 ，各节点上的层进
行串行计算 。因此 ，Pipeline 并行不能减少推理总延时 ，只
能减小节点存储量 。在满足延时指标的前提下 ，Pipeline 并
行度不宜过大 ，只要节点显存足够支持本节点的 Transformer
层即可 。
3.2.2 计算优化
在Transformer 的自注意力中 ，矩阵乘的计算复杂度为序
列长度的平方 。当序列较长时 ，计算量会大幅增加 。自注意
力的非线性算子虽然计算量不大 ，但计算效率低 。这两点都
会使延时增大 。为了缩短延时 ，我们可以使用多种方案减少
计算步骤 ，降低计算量 。
3.2.2.1 KV Cache
大语言模型由解码器组成 ，是生成式模型 。在推理时 ，
输入一段提示 ，能够生成一段回答 。生成的回答并不是一次
生成所有 tokens ，而是每次推理生成一个 token ，这个 token
再和输入的所有 tokens 拼接在一起 ，作为下一次推理的输
入，生成下一个 token 。这样反复进行 ，直到模型输出结束
符（EOP）为止 。
生成式模型推理的弊端是很明显的 。每次输入的所有
tokens ，都要参与注意力计算 。除了最新 token ，前面的其他
tokens 的计算与前次推理相同 ，是重复计算 。为了解决这个
问题 ，可使用 KV Cache 。它可以将每次推理计算出的 tokens
的特征缓存在显存中 ，下次推理直接取用 ，无须重复计算 。
这样每次推理 ，输入只有一个最新 token ，自注意力的计算
量可以大幅下降 。
大语言模型推理过程属于带宽受限型 ，KV Cache 虽然▼表2 Llama 2模型各层算术强度
Batch
大小
1
128
512
4 096算子
MHA（线性投影 ）
MHA（矩阵乘 ）
FFN（线性投影 ）
其他
总计
MHA（线性投影 ）
MHA（矩阵乘 ）
FFN（线性投影 ）
其他
总计
MHA（线性投影 ）
MHA（矩阵乘 ）
FFN（线性投影 ）
其他
总计
MHA（线性投影 ）
MHA（矩阵乘 ）
FFN（线性投影 ）
其他
总计计算量 /
TFLOPs
42.95
10.74
57.98
0.02
111.69
5 497.56
1 374.39
7 421.70
2.84
14 296.49
21 990.23
5 497.56
29 686.81
11.37
57 185.98
175 921.86
43 980.47
237 494.51
91.00
457 487.84访存量 /
TMOPs
42.46
10.74
57.99
0.02
111.21
43.79
1 374.56
59.22
2.41
1 479.99
47.82
5 498.23
62.95
9.65
5 618.65
85.40
43 985.83
97.71
77.19
44 246.13算术强度
1.01
1.00
1.00
1.18
1.00
125.53
1.00
125.32
1.18
9.66
459.85
1.00
471.61
1.18
10.18
2 059.93
1.00
2 430.59
1.18
10.34
FFN：前馈网
MHA ：多头注意力TFLOPs ：万亿次浮点运算
TMOPs ：万亿次内存访问
13