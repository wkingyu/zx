低资源集群中的大语言模型分布式推理技术 冯文佼   等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2的是在资源受限的环境下 ，实现更大规模的 LLM 推理 。其
中，这一机制包含两个核心模块 ：最小化显存占用机制和预
加载机制 。通过将 Transformer 模型的每个 Layer 视为独立状
态，并将参数分散到不同 GPU 上，最小化显存占用机制确
保每个计算单元仅保留当前必需的参数片段 ，大幅降低了总
体显存需求 。同时 ，预加载机制能在当前计算进行前加载下
一步所需的参数 ，有效消除了推理过程中的等待时间 ，进一
步提升了推理效率 。这两个模块的协同工作 ，使得我们的显
存管理策略能够在减少资源消耗的同时保证模型推理的连续
性和吞吐 。
1）最小化显存占用机制
已知 Transformer 模型由多个 Layer 串连而成 ，我们将每
个Layer 视为一个独立状态 ，同时 ，根据新型分布式推理范
式将每个 Layer 中的参数切分为不同的部分 。每个 GPU 仅维
护对应的部分 。对于特定的推理计算 ，用b表示批量大小 ，
s表示输入序列长度 ，n表示输出序列长度 ，h表示隐藏维
度，L表示 Transformer 层数 ，a表示 attention heads 。考虑有
N个GPU 执 行 推 理 。对 于 batch X ，GPUn处 理 Layer 1到
Layer L的sn1~sn2参数片段 ，包括an1~an2注意力头和相应的
MLP 参数切片 。针对 batch X 中的某个 prompt 生成一个词元
过程 ，具体的显存管理与调度流程如图 3所示 。
显存管理与计算线程并行运行 ，前者负责模型参数在显
存与内存间的调度 ，后者执行 GPU 上的张量并行计算 。在推
理的每个步骤 i中，系统识别 Layer(i)作为当前的活动状态 。
对于 GPUn，其计算线程专注于执行 Layer(i)内部特定的 s1~s2
参数切片的计算任务 。与此同时 ，显存管理线程负责从显存中卸载掉之前步骤 Layer(i-1)的s1~s2参数切片和对应注意
力头的 KV缓存 。与传统方法相比 ，显存需完整存储模型参
数及 KV缓存 。本策略确保计算卡在任一时刻仅保留必要的
参数 ，从而在资源受限的环境中实现更大规模的模型推理 。
2）预加载机制
然而 ，上述的串行计算存在一个明显的缺陷 ：在完成
Layer(i)的计算后 ，推理过程需等待 Layer(i+1)的参数加载
至显存 ，这显著降低了推理效率 。因此 ，我们引入了预加载
机制 ，允许显存管理线程在 Layer(i)计算进行时 ，提前将
Layer(i+1)的s1~s2参数切片和对应注意力头的 KV缓存从内
存预加载至显存 。该机制使用少量的显存 ，消除了计算停
滞，保障了推理流程的无缝衔接 。
3）支撑的模型范围对比分析
在资源受限条件下 ，通过上述细粒度的显存管理与调
度，这套范式理论上可以支撑多大的模型 ？考虑 fp16中的
GPT3-175B模型 （L=96，h=12 288） ，峰值时存储 KV缓存的
总字节数为 4×b×h×(s+n)。模型所需的总显存为 350 GB，
存储 KV缓存所需的总显存为 816 GB（其中 ，b=16，s=512，
n=32） ，总显存需求约为 1 166 GB，平均每层需要 12 GB显
存。在四卡系统中 ，每卡理论上承担 3 GB，即使考虑额外
的缓冲和预加载空间 ，每卡的显存使用也不会超过 6 GB。
相比之下 ，传统 GPU-only 方案每卡需承担 290 GB。因此 ，
我们的方法可以推理比 GPU-only 的解决方案大 48倍的模型
（每卡承担 6 GB与290 GB） ，超越 DeepSpeed Inference 的25
倍[3]。这表明我们所提方法在模型扩展性方面具有优越性 。
总的来说 ，此方法在保证推理性能的基础上 ，通过细粒
度管理与调度显存 ，在显存受限
的硬件环境中也能高效推理更大
规模的模型 ，极大提高了硬件资
源的利用率和成本效益 。
3 实验评估
本节我们将围绕两个方面来
评估所提方案的性能 ：1）对首词
元生成延迟的降低以及每秒生成
词元吞吐量的提升效果 ；2）量化
本 系 统 显 存 管 理 与 调 度 机 制 的
优势 。
3.1 实验平台设置
在 构 建 系 统 时 ，我 们 选 用
 图3 细粒度的显存管理与调度流程图GPU：图形处理器图例：Layer 1：
s1~s2参数切片Layer 2：
s1~s2参数切片Layer 3：
s1~s2参数切片Layer L-1：
s1~s2参数切片Layer L：
s1~s2参数切片内存
显存
GPUn加载 GPUn所需的模型参数 ：
预加载
Layer 1 Layer L
预加载
Layer 1
Layer 2预加载
………………
卸载
Z1Z2X Z1卸载
Layer 3 Layer L
预加载
……………………
…………
Z2Z3………………
……
……
……
Layer LLayer L-1
……
……预加载
……ZL-1ZL初始化
Step 1
Step 2Step 3
Step L-1
Step L
47