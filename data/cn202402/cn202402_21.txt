大语言模型算法演进综述 朱炫鹏  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2信号进行处理 ，得到一个输出连续时间信号 ，信号的长度没
有限制 。调整 SSM 的参数 ，可以使输出信号成为输入信号的
特征 。音频 、视频数据本身就是连续时间信号 ，适合用 SSM
处理 。但文本序列是离散的 ，且信息密度大 ，不能直接用
SSM 处理 ，因此需要对 SSM 做离散化及一些调整 。
语言模型加入调整后的 SSM，有些取得了较好的效果 ，
目前常见的 SSM 语言模型有线性注意力[53]、S4[54]、H3[55]、
Hyena[56]、RetNet[57]、接受权重键值 （RWKV ）[58]、Mamba[59]
等。本文中 ，我们主要介绍 S4和Mamba 。
4.2.1 S4模型
S4模型的连续 SSM 公式为 ：
h'(t)=Ah(t)+Bx(t)， （11）
y(t)=Ch(t)， （12）其中 ，x(t)是输入信号 ，h(t)是隐藏状态 ，h'(t)是h(t)的变
化率 ，y(t)是输出信号 ，A、B、C是参数矩阵 。
SSM 离散化后才能用于处理文本序列 ，具体做法是根据
步长Δ将A、B离散化为Aˉ、Bˉ，得离散化 SSM 公式为 ：
ht=Aˉht-1+Bˉxt， （13）
yt=Cht， （14）
其中 ，xt是输入序列中的第 t个token ，ht是第t个隐藏状态 ，
yt是第t个输出 。
以上公式是递归的 ，序列长度不受限制 。如果已知序列
长度 ，可以进行展开 ，得：
yk=CAˉkBˉx0+CAˉk-1Bˉx1+⋯+C------ABxk-1+CBˉxk。 （15）
此式可转换为卷积形式 ：图5 单设备混合专家与多设备 GShard 专家并行[51]FFN：前馈网      MoE ：混合专家Transformer
编码器MoE Transformer
编码器MoE Transformer 编码器在设备上的分布
编码器输出
FFN
多头注意力
输入嵌入向量 +
位置编码编码器输出
输入嵌入向量 +
位置编码FFN
多头注意力
FFN1FFNE……
门控MoENx(N/2)x编码器输出
（分片 1）
多头注意力
FFN1(N/2)x (N/2)x
模型并行
MoE
……
设备
1……E
设备 1 设备 E
输入嵌入向量 +
位置编码  （分片 1）输入嵌入向量 +
位置编码  （分片 E）FFN编码器输出
（分片 E）
多头注意力
FFNE
门控累加和归一化累加和归一化累加和归一化
累加和归一化
累加和归一化
累加和归一化
多头注意力累加和归一化
FFN
累加和归一化
多头注意力累加和归一化
多头注意力累加和归一化 累加和归一化
All-to-All 分发累加和归一化 累加和归一化
All-to-All 收集
门控累加和归一化
17