大语言模型时代的智能运维 裴 丹   等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2LLM 在AIOps 领域的落地应用存在如下技术挑战 ：
1）AIOps 系统对错误的容忍度低 ，因为一旦决策错误
将带来灾难性后果 。但是 ，通用 LLM 容易出现幻觉 ，错误
率较高 。
2）运维人员往往要求 AIOps 系统输出的结果具有可解
释性 ，以便于他们判断结果的准确性并采取相应的运维措
施。但通用 LLM 往往是黑盒模型 ，可解释性欠佳 。
3）AIOps 领域的严肃语料数量不足且质量欠佳 ，但训
练或微调 OpsLLM 往往需要大量高质量语料 。
4）大部分企业通常不愿意为 AIOps 耗费太多计算资源 ，
往往要求 OpsLLM 具有较低的部署开销 。但是 ，通用 LLM 的
部署 、微调和应用往往耗费大量的计算资源 。
5）当前 ，通用 LLM 呈现百花齐放 、日新月异的局面 ，
因 此 如 何 选 择 最 优 的 通 用 LLM ，是OpsLLM 亟 待 解 决 的
挑战 。
6）通用 LLM 往往无法直接处理时间序列 、知识图谱 、
拓扑结构等多模态运维数据 ，但企业往往积累了海量多模态
运维数据亟待 OpsLLM 处理 。
7）企业往往已开发了大量 AIOps 、自动化运维工具 ，
需要与 OpsLLM 结合起来 ，发挥它们的价值 。
虽然目前将 LLM 应用到 AIOps 领域面临着一些挑战 ，但
前述所有技术挑战都有相应的技术思路可供解决 ，具体而言
有以下 6点：
1）为了避免幻觉 ，增强模型的可解释性 ，可以采用检
索增强 （RAG）的方式 ，增加显式知识的占比 ，包括思维
链、思维树 、思维图和知识图谱 ，并通过 “有据可依 ”的生
成策略提供原文引用 。
2）解决严肃语料不足的问题可以通过由易到难的课程
学习方式进行训练 ，以逐步提高模型对运维领域的理解和适
应能力 。
3）针对 “私有部署训练和部
署开销都要低 ，私域数据的数量 、
质量不足 ”的问题 ，可以进行模型
分层 ，通过在公域进行预训练 、微
调和提示工程 ，训练一个针对运维
领域的 LLM （即L1层LLM） 。在私
有部署时 ，可以避免预训练和微
调，而是通过检索方式融合本地知
识库 ，以文档和提示作为便捷的知
识工程手段 ，并通过降低模型的精
度来降低私有部署的一系列推理
开销 。4）在底座选型时 ，应尽量与开源 LLM 的底座解耦 ，以
便更灵活地应对不同需求和场景 。
5）对于结构化 、多模态和实时数据的处理 ，可以建立
专门的多模态基础模型群 ，并构建相应的工具智能体 ，以实
现对这些数据的有效处理和分析 。
6）对于存量的 AIOps 小模型工具和自动化运维工具 ，
可以利用工具智能体的方式将其融入到多智能体架构中 ，以
实现更高效 、更智能的运维流程 。
这些措施将有助于克服技术难题 ，推动 LLM 在AIOps 领
域的发展和应用 。
4 大模型时代的 AIOps落地建议
针对上述具体的挑战 ，我们都有相应解决方法和应对手
段。从方法论角度看 ，大模型时代技术日新月异 ，因此我们
更需要更加系统地 、有规划地设计大模型时代的 AIOps 落地
路径 ，少走弯路 ，用有限的资源获得最大化的落地效能 。具
体而言 ，本文中我们总结了大模型时代 AIOps 的3个重要的
设计准则或重要方向 。
4.1 训练“懂运维语言 ”的大语言模型 OpsLLM
在运维这一严肃领域 ，迫切需要训练一个 “懂运维 ”的
LLM ，而非仅仅是一个通用的 LLM 。这一模型必须具备真正
理解输入文档和上下文的能力 ，而不是仅提供大致的答案 。
举例而言 ，如图 4所示 ，开源的 LLM 可以被视为训练有素的
本科生 ，他们博闻强记 ，但如果将这些本科生直接投入运维
工作岗位 ，他们可能无法理解其中的内容 ，甚至不了解相关
术语 ，从而难以胜任工作 。因此需要利用大量与运维相关的
语料对模型进行训练 、微调和优化 ，以使其能更好地理解运
维上下文 ，此时的模型可以被视为运维专业研究生 。只有这
样，它才能在实际的运维场景中发挥作用 。这一观点与中文
图4 运维大语言模型的模型栈私有部署运维大语言模型私有部署运维大语言模型
基于私域运维数据 ：提示工程 、外挂知识库检索
运维大语言模型运维大语言模型
基于公域运维语料 、知识库 ，进行预训练 、微调、提示工程
松耦合的通识大语言模型底座松耦合的通识大语言模型底座L2
L1
L010年运维工龄 ，
5年司龄的运维员工
运维专业研究生 、
5年运维工龄
大学计算机类专业
本科生
60