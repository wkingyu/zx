智能算力核心基础系统软件的现状与展望 郑纬民  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 23.2 AI编译器
AI编译器的主要用途和意义在于自动化地提高模型的
执行效率和性能 ，同时保证优化前后程序的等价性 。根据计
算图这一通用的程序抽象 ，AI编译器的主要技术可分为高
层次的计算图优化和低层次的算子优化 。
目 前 存 在 多 个 被 广 泛 使 用 的 AI编 译 器 系 统 ，例 如
TVM[35]和XLA[36]。XLA 通过静态图编译和优化技术 ，提供了
高性能的执行引擎 。它能够将 TensorFlow 等框架的计算图编
译为高度优化的底层代码 ，利用冗余消除 、等价计算图替换
和算子融合等技术加速计算 。此外 ，XLA 具备内存优化和低
精度计算等多种优化 ，进一步提高硬件加速器的利用效率 。
TVM 提供了一套端到端的编译和优化工具链 ，旨在加速深
度学习模型的推理和训练过程 。TVM 的核心思想在于针对
用户给定的计算逻辑 ，通过自动调度计算的执行方案 ，自动
化地优化和生成算子的执行代码 。这使得 TVM 能够以相对
较小的开发成本为不同硬件平台生成高效的代码 ，提供了一
个跨平台的算子生成工具 。
在中国 ，以PaddlePaddle[14]、Mindspore[15]为代表的通用
深度学习框架均集成了大量的 AI编译器技术 ，以提高程序
的执行效率 。针对中国硬件加速器种类多的现状 ，目前业界
也出现了如 InfiniTensor[37]、PowerFusion[38]等一系列新的框
架，以提升国产硬件加速器的利用率 。InfiniTensor 框架探索
了基于张量表达式推导的优化技术 ，尝试在更大的优化空间
中发掘新的优化机会 。PowerFusion 通过细粒度算子拆分的
方式 ，实现了更为高效的算子融合方案 。
目前 ，AI编译器的发展仍然存在较大空间 。一方面 ，
针对国产加速器硬件利用率低的问题 ，加强对国产硬件平台
的编译优化支持 ，提供更广泛的适配能力 。另一方面 ，可以
进一步优化编译器的自动优化算法 ，提高编译器生成的底层
代码的效率和性能 。此外 ，加强与中国深度学习框架的集
成，提供更便捷的编译和优化工具 ，也具有重要意义 。
4 基础支撑软件
大模型计算具有很高的复杂性 ，除了上述关键组件 ，还
需要众多基础支撑软件 ，主要包括调度系统 、容错系统 、内
存分配系统和存储系统 。这些系统软件对大模型的易用性和
高效性亦有重要意义 。
4.1 调度系统
超大规模的模型训练不仅会带来巨大的计算成本 ，而且
需要依赖大型的集群计算系统 。在这样的背景下 ，充分挖掘
和利用大规模集群计算能力变得非常关键 ，而一个高效且稳定的调度系统可以大幅度降低训练成本并显著提升训练效
率。具体而言 ，调度器作为大规模集群系统的核心 ，主要有
以下 3个功能 ：
第一 ，弹性调度 。调度器能够根据大模型训练任务的需
要和集群的当前状态 ，动态分配资源 ，从而确保训练过程中
资源的最优化利用 。
第二 ，资源管理 。调度器负责集群各种资源的规划和管
理。大模型训练对计算 、存储有着极大的需求 ，因此各种不
同的资源 ，包括 CPU、GPU 和存储等要进行协同工作 。调度
器需要确保在有限的资源下最大化利用各个训练任务的性
能，避免资源浪费 。
第三 ，队列管理 。调度器能够根据设定的优先级对训练
任务进行排序 ，管理多任务的执行队列 。调度器结合不同任
务的资源需求 、优先级高低来进行资源在时间和空间上的分
配，从而确保每个训练任务都能获取到足够的资源并及时
完成 。
在国际上 ，Kubernetes （K8s）[39]是目前主流大模型训练
在大规模集群系统上的调度器 。它简化了容器化应用程序的
部署 、扩展和管理工作 ，成为了大规模集群管理和调度的主
流软件 。而在当前大模型兴起的背景下 ，Kubernetes 同样凭
借它在大规模系统上的高适用性 、GPU 等资源的细粒度管理
和弹性调度 ，以及训练任务部署的灵活性等 ，成为目前大模
型训练主要使用的软件 。
在中国 ，华为的 ModelArts[20]等平台也提供了高效的人
工智能开发环境和强大的集群管理功能 。它支持弹性调度 ，
可以灵活地管理包括英伟达 GPU 和国产加速器在内的多种
硬件资源 。但是 ，目前各家调度器仍存在一些尚未解决的问
题，例如 ：大模型训练调度中硬件资源选择和不同并行训练
策略的协同 、多种训练任务的稳定性 ，以及效率管理等
问题 。
总体来说 ，尽管目前大规模集群调度器已经相对成熟 ，
但为了满足不断发展的大模型训练需求 ，在大规模系统中更
高效地实施调度策略仍然是值得进一步研究的内容 。
4.2 容错系统
容错在当今 AI领域扮演着至关重要的角色 ，其主要作
用是确保训练和推理过程的稳定性及可靠性 。在大规模系统
运行过程中 ，难免出现软硬件故障或异常 ，有效的容错技术
可以确保系统在面对各种异常情况时能够继续正常运行 ，避
免训练终止 ，从而节约时间和资源 ，并提高大模型训练的效
率。大模型训练的容错技术包括检查点恢复 、动态调整学习
率、硬件故障处理等 ，其中最常用的容错技术是基于检查点
05