低资源集群中的大语言模型分布式推理技术 冯文佼   等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2关注主机内外带宽差异以及如何最大化 LLM 推理的潜力 。
在本文中 ，我们研究了一种面向弱算力 、小显存的高兼
容的分布式推理范式 。该范式能支持 All-Reduce 通信原语 。
具体而言 ，我们揭示了在进入非线性层之前 ，LayerNorm 和
Broadcast 两个操作是可交换的 。基于此我们提出了一个创新
方 案 ：将 传 统 的 Reduce+LayerNorm+Broadcast 算 子 简 化 为
All-Reduce+LayerNorm 算子 。这一新范式旨在全面支持 All-
Reduce 通信原语 ，使之能在不同场景中利用多样化的通信
库来实现高效的分布式推理 。
在中低端数据中心内机架规模下涉及跨主机的 All-
Reduce 通信时 ，分布式推理低带宽网络会带来明显的性能
瓶颈问题 。为解决这一问题 ，我们提出了一种面向主机内外
差异带宽的高性能 All-Reduce 通信算法 。具体来说 ，我们根
据主机内和机架内带宽特点的差异性 ，实现基于通信树的高
效All-Reduce 组通信库 ，有效组织分布式推理的中间计算结
果聚合与分发 ，从而减少跨主机通信并充分利用内部高速
带宽 。
此外 ，我们还探索了面向 LLM 、小显存集群的显存管理
与调度 ，旨在低资源环境中实现更大规模与更高效的 LLM
推理 。我们采用了动态调度模型参数的方法 ，包括及时回收
未使用的参数空间以减少显存占用 ，并预加载即将使用的参
数以消除轮次间的等待时间 ，从而无缝加速推理过程 。这种
策略通过细粒度控制显存的使用 ，降低了峰值显存需求 ，即
使在显存有限的硬件条件下也能高效地执行大规模模型推
理，在确保推理性能的同时提高硬件资源的使用效率和成本
效益 。
为了实现上述想法 ，一些技术难题仍需要解决 ：难题 1：如何保证本文提出的范式在保持理论计算正确
性的同时 ，与现有张量并行范式具有等价的推理计算效率和
资源消耗 。
难题 2：如何保证本文提出的分层聚合算法在理论计算
结果正确的前提下 ，最大限度地减少由机架内带宽的低带宽
网络引起的通信开销 。
难题 3：基于新型分布式训练范式 ，如何精准把控推理
过程中所需的模型参数在显存中的加载和卸载时机 ，即明确
何时将这些相关数据载入显存以进行有效的计算 ，以及何时
将其从显存中移除以优化资源使用 。
2 方案设计
2.1 面向弱算力 、小显存的高兼容的分布式推理范式
Megatron-LM 采用张量并行来应对大规模模型对高算力
和大显存的强依赖 ，并通过引入 Reduce+LayerNorm+Broad ‐
cast算子确保计算的准确性 。然而 ，这种中心化的并行范式
存 在 单 点 瓶 颈 ，并 且 不 支 持 如 信 息 传 递 接 口 （MPI） 、
NVIDIA 集合通信库 （NCCL ）等主流 All-Reduce 通信库 ，影
响了其兼容性和效率 。为此 ，我们研究了一种兼容性更好的
张量并行范式 。该范式能支持 All-Reduce 通信原语 ，使之能
在不同场景中利用多样化的通信库来实现高效的分布式推
理，并且与现有张量并行范式一样具有等价的推理计算效率
和显存消耗 。具体如图 1所示 ，在进入 MLP 之前 LayerNorm
和Broadcast 两个操作是可交换的 。基于这一关键发现 ，本
文 提 出 将 Reduce+LayerNorm+Broadcast 算 子 合 并 为 All-
Reduce+LayerNorm 算子 。接下来 ，我们将从理论正确性和资
图1 面向弱算力 、小显存的高兼容分布式推理范式示意图Reduce
并行LayerNorm
串行 并行BroadcastReduce+LayerNorm+Broadcast 算子
更新为All-Reduce+LayerNorm 算子
LayerNorm
并行 并行All-Reduce
全连接前馈网络 掩码多头自注意力线性层
线性层
线性层线性层 线性层 线性层Q
K
VK K Dropout输入层归一化 层归一化 层归一化
输出
缩放点积
注意力Dropout
45