大模型关键技术与应用 韩炳涛  等 企业视界
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2Row Parallel ，Output Embedding 采用 Column Parallel ；Drop ‐
out/Layer Norm/Residual Connections 等 操 作 都 没 有 做 并 行
拆分 。
节点间带宽对模型并行效率有较大影响 ，高速串行计算
机扩展总线标准 （PCIE ）的理论带宽为 32～64 Gbit/s ，通常
可以满足大模型并行推理需求 。模型参数量越大 、Batchsize
越大 ，节点间的通信效率就越高 ，使用模型并行获得的收益
越明显 。
3.5 服务调度优化
服务调度优化主要考虑的是系统同时为多个用户服务时
如何尽可能地提升资源利用率 ，相关优化主要包括 Con‐
tinuous Batching 、Dynamic Batching 和 异 步 Tokenize/Deto ‐
kenize 。其中 ，Continuous Batching 和Dynamic Batching 主要
围绕提高可并发的 Batchsize 来提高吞吐量 ，异步 Tokenize/
Detokenize 则通过多线程方式将 Tokenize/Detokenize 执行与模
型推理过程时间交叠 ，从而实现降低时延目的 。
Continuous Batching 和Dynamic Batching 的思想最早来自
文献 [41]。Continuous Batching 的原理是 ：将传统 batch 粒度
的任务调度细化为 step级别的调度 ，这解决了不同长短序列
无法合并到同一个 batch 的问题 。调度器维护 3个队列 ，分
别为 Running 队列 、Waiting 队列和 Pending 队列 。队列中的
序列状态可以在 Running 和Waiting/Pending 之间转换 。在生
成每个 token 后，调度器均会立刻检查所有序列的状态 。一
旦序列结束 ，调度器就将该序列由 Running 队列移除并标记
为 已 完 成 ，同 时 从 Waiting/Pending 队 列 中 按 先 来 先 服 务
（FCFS ）策略取出一个序列添加至 Running 队列 。
Batching 优化技术可有效提升推理吞吐量 ，目前已在
HuggingFace TGI 、vLLM 、TensorRT-LLM 等多个推理框架中
实现 。
3.6 推理阶段的安全漏洞和防护
推理阶段的安全漏洞不仅可能危及用户的隐私和数据安
全，还可能被恶意利用 。下文中 ，我们将详细介绍推理阶段
可能遇到的漏洞及其原理 ，以及如何通过一系列防护措施来
提高大模型的安全性 。
推理阶段常见的攻击手段包括 ：1）越狱攻击 ：通过某
些方式使大模型产生退化输出行为 ，诸如冒犯性输出 、违反
内容监管输出 ，或者隐私数据泄漏的输出 。2）提示注入攻
击：通过注入恶意指令 ，可以操纵模型的正常输出过程 ，导
致模型产生不适当 、有偏见或有害的输出 。3）成员推理攻
击：通过分辨一条数据是否属于模型的训练集 ，可以使攻击者获得训练集数据所共有的特征 ，在训练数据集敏感的应用
场景中 （例如 ，生物医学记录和位置跟踪 ） ，成功的成员推
理攻击会导致严重的隐私泄露和安全威胁 。
针对以上漏洞 ，我们可以实施的防护手段包括 ：1）越
狱攻击防御 ：基于预处理技术如指令净化 、关键词过滤 、恶
意模型检测等 ，检测并清理输入或输出中的有害信息 ，通过
语义内容过滤防止大模型生成不受欢迎或不适当的内容 ，这
可以有效减轻潜在的危害 。2）提示注入攻击防御 ：重新设
计提示指令是一类预防提示注入攻击的方法 ，例如 re-
tokenization[42]、paraphrasing[42]等。re-tokenization 是为了打破
在提示中注入的恶意指令 （如任务忽略文本 、特殊字符和虚
假响应等 ）的顺序 。paraphrasing 可以干扰注入数据的序列 ，
如注入指令及特殊字符插入 ，减弱提示注入攻击的有效性 。
还有一些防御方法是基于检测的 ，侧重于确定给定数据提示
的完整性 ，如困惑度检测就是一种基于提示的检测方法 ，它
向数据提示添加信息或指令 。这就会降低质量 ，并导致困惑
度增加 。因此 ，如果数据提示的困惑度超过指定阈值 ，我们
则认为数据提示存在问题 。3）成员推理攻击防御 ：Salem 等
提出了第一个针对成员推断攻击的有效防御机制[43]，具体方
法包括 Dropout 和模型堆叠 。Dropout 被定义为随机删除一定
比例的神经元连接 ，可以减轻深度神经网络中的过拟合 ，这
是成员推断攻击实现中的一个重要因素[43]。模型堆叠防御背
后的思想是 ，如果目标模型的不同部分使用不同的数据子集
进行训练 ，那么整体模型有望表现出更低的过拟合倾向 。差
分隐私[44]也是目前对成员推理攻击最突出的防御手段之一 ，
通过给模型的输出增加噪声 ，使得攻击者无法根据输出结果
在统计上严格区分两个数据集 。
3.7 新兴技术
我们将传统优化技术引入大模型推理的同时 ，也在探索
从大模型自回归解码特点出发 ，通过调整推理执行过程来进
一步提升推理性能 。并行推测解码作为新兴的推理技术 ，可
以在不损失精度的前提下提高推理速度 。
投机采样[45]是一种并行推测解码算法 ，开创了 “小成本
生成 +大模型验证 ”的推理技术路线 。该算法在已有大模型
的基础上 ，引入一个小模型执行串行解码来提升速度 ，原大
模型执行并行评估采样 ，保证生成质量 ，这在保证精度一致
性的同时降低了大模型解码的次数 ，进而提升了推理效率 。
例如 ，我们基于 HuggingFace Transformers 库实现该算法 ，使
用Pythia- 6.9B作为基础模型 ，Pythia- 160M作为近似模型 ，
在A100-PCIE- 40GB下可以取得 3.9倍的推理速度提升 。
由于投机采样算法的巨大潜力 ，有多项工作在其基础上
83