基于存算一体集成芯片的大语言模型专用硬件架构 何斯琪  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2经网络计算芯片研究和大模型实际部署的重要前进方向 。通
过电路与架构的协同创新 ，存算一体架构试图打破存储器和
计算器之间的壁垒 ，实现数据搬移效率的提高或数据搬移次
数的减少 ，从而提高芯片的计算能效 。
然而 ，目前已有的神经网络计算芯片可扩展性欠佳 ，无
法完全适应大模型的推理需求 。在上述背景下 ，处理器领域
的巨头已经将目光投向了集成芯粒 （Chiplet ）这一新兴技
术。集成芯粒技术最早由加利福尼亚大学圣塔芭芭拉分校
（UCSB ）大学的谢源教授于 2017 年国际计算机辅助设计会
议（ICCAD ）上提出[4]。与单芯片 SoC方案不同 ，集成芯粒
方案先将多个小颗粒芯片独立设计并实现 ，然后通过先进封
装技术重新组装 ，从而完成系统上的功能集成 。美国 Intel
公司 、AMD 公司 、英伟达公司的服务器 /数据中心芯片都已
开始广泛采用集成芯粒方案[5-7]。这些方案将高性能计算核
心设计为模块化芯片 ，通过 2.5D/3D封装技术 、高速片间互
联技术和有源基板技术将计算核心芯片模块集成 。在不明显
增加设计复杂度的前提下 ，保证芯片的良率 ，延续了后摩尔
时代芯片算力提升 。这一趋势为硬件设计提供了更为灵活和
高效的解决方案 ，以适应不断增长的大型模型算力需求 。
1 大模型对数据中心的挑战
1.1 集成芯片技术
以ChatGPT 为代表的人工智能 （AI）大模型在参数规模
和系统算力需求上呈现出指数级的增长趋势 。当前 ，能够支
持大型模型的数据中心和超级计算机普遍采用以 xPU+ 主机
内存缓冲器 （HBM ）集成芯片为核心的高性能处理器芯片
系统 。如图 2所示 ，这些大算力芯片具备 PFLOPS 级算力和
100 GB级存储性能 ，例如 Nvidia H 100 图形处理器 （GPU）拥有 2 PFLOPS （每秒执行 1 000万亿次浮点运算 ）的算力 ，
AMD Instinct MI 300拥有 383 TFLOPS （每秒执行 1万亿次浮
点运算 ）的算力 ，华为昇腾 910 B则具备 256 TFLOPS 算力
等。传统的超大规模和超大面积的单芯片 SoC方案已经面临
着诸多问题 ，包括利用率低 、良率低 、验证复杂度高以及设
计成本激增等 。同时 ，集成电路制造已经达到了光刻掩膜版
的最大面积上限 ，而30.48 cm（12英寸 ）晶圆的掩膜也在光
刻机的要求下存在上限 ，最大芯片设计面积为 858 mm2。在
这样的背景下 ，单芯片 SoC的算力进一步扩充空间受到限
制，潜在的良率问题和面积限制使得算力的提升变得更加困
难。同时 ，自2023 年起 ，美国进一步加强了针对中国芯片
产业的出口限制 ，对总处理性能和算力密度超过超过规定的
芯片实施了更加严格的管制 。
为了缩小智能计算和处理器芯片技术上的差距 ，采用微
纳架构工艺将多个芯片 （粒）集成已经成为克服单芯片制造
最大面积极限和芯片电路规模瓶颈的重要手段 。不同于单芯
片方案 ，集成芯片方案通过使用先进封装技术将多个小颗粒
芯片组件组装在一起 ，实现了系统上的功能集成 。这种方法
将大型昂贵的 SoC分解为体积更小 、良率更高且更具成本效
益的单芯片 ，同时也有助于缩短设计周期 ，降低成本 。集成
芯片技术已成为高性能处理器不可或缺的组成部分 ，而它正
朝着 3D多层堆叠 、更多种类的芯片以及更大规模集成的方
向发展 。这一发展趋势的目标是进一步满足大型模型对硬件
性能的不断增长的需求 ，适应日益增加的计算和处理任务 。
1.2 大模型部署的带宽瓶颈
以图 3中展示的拥有 70亿参数的大型模型 （LLAMa 2-
7B）为例 ，该大型模型的每一层多头注意力都包括多个连
续前馈 （FCL）计算 。与此相关的单层参数量达到 2.03亿，
而32层的参数总量达到 65亿，占用整体系
数和计算的 85%以上 ，远超过单一互补金属
氧化物半导体 （CMOS ）芯片的片上存储空
间。注意力模块的计算存储要求则相对较
低，CPU/ 中等性能网络处理器 （NPU）即可
完成 。在大型模型推理中 ，如要满足每秒 1
万个令牌的实时要求 ，即令牌速率为 10 000
个/秒，对GPU 的带宽需求将达到 64 TB/s ，
而当前的 HBM 3带宽仅为 0.8 GB/s 。因此 ，
对于十亿级以上规模的大型模型网络应用场
景，现有的 GPU/TPU+DRAM 分离计算架构
难 以 满 足 不 断 增 长 的 模 型 参 数 传 输 带 宽
需求 。
CPU：中央处理器
EFLOPS ：每秒执行 100亿亿次浮点计算
GPU：图形处理器HBM ：主机内存缓冲器
SRAM ：静态随机存取存储器
图2 超算中心总算力和集成芯片数排名 2023  新晋超算第二 美国第三台 E级超算系统 2022  Top 500 第一 2022  Top 500 第二
超算
中心
总算力
芯片组
集成芯片
Chiple 数GPU+SRAM+
HBM+Act Int .（47）CPU+GPU+HBM+
Acttive Int .（21)GPU+SRAM+HBM GPU+SRAM+HBM美国 阿贡 Aurora 美国 劳伦斯  EL Capitan 美国 橡树岭  Frontier 日本 富岳 Fugaku
0.442 EFLOPS 1.102 EFLOPS 2 EFLOPS 2 EFLOPS
Ponte Vecchio MI300/300X AMD EPYC+MI 250XFujistu
AF64x
38