大模型训练技术综述 田海东  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2训练的瓶颈 ，此时需要通过通信和计算重叠等方式降低通信
等待时间[19]。
3） 数据预处理卸载
将数据预取和数据预处理的过程卸载到 GPU 等设备上 ，
构建高效的数据流水线 ，可以减少数据加载的等待时间 ，让
训练过程更加流畅 。DALI[20]是专门为 GPU 优化的数据加载
库，通过在 GPU 上运行数据处理管道从而加速数据预处理
过程 。DALI 的性能优于传统的数据流水线 ，但代价是占用
了GPU 有限的计算和内存资源 。发掘训练模式和数据特征 ，
进行数据压缩 ，有助于实现 GPU 内存优化[21]。目前 PyTorch
等主流深度学习框架都已经支持 DALI 的使用 。
此外 ，数据流分析工具如 DS-Analyzer[22]，可以针对具
体的训练场景 ，精确发现数据流中的性能问题 。对数据停滞
进行预测和分析 ，能够为提高训练效率指明具体的改进方
向，例如 ：CoorDL[22]验证了在特定情况下 ，模型训练能够获
得比 DALI 更高的资源利用率和更好的性能 。
3 模型初始化及评估
这一章节中我们主要探讨两个问题 ：如何做好预训练大
模型的初始化准备 ，以及如何在训练过程中确定更好的模型
评估指标 ，具体包括模型规模的选择 、模型超参数的初始化
设置 、模型的评估等方面 。
3.1 模型规模选择
在进行预训练之前 ，了解大模型的扩展法则可以帮助我
们很好地平衡模型大小 、数据的规模以及计算量之间的关
系。这里我们给出两种大模型的扩展法则 ，具体说明如下 ：
1） KM扩展法则
Decoder-only 的模型算力有如下关系 ：
C~τT=6PD， （1）
其中 ，C表示模型的总计算量 ，τ表示吞吐量 ，T表示训练时
间，P表示模型的参数量 ，D表示 token 数。
2020 年OpenAI[23]团队首次通过实验给出了模型性能和
模型参数量 、数据规模 、模型计算量之间的幂律关系 。由幂
律关系发现 ，在相同算力下模型的参数量更重要 。
2） Chinchilla 扩展法则
Google 的DeepMind 团队提出了 Chinchilla 扩展法则[24]。
他们在一个更大范围 （7 000万到 160亿参数 ）的模型和更
大范围 （50亿到 5 000亿tokens ）的数据条件下探讨上述 KM
扩展法则 ，得出一个系数不同的幂律关系 ，即Chinchilla 扩
展法则 。Chinchilla 扩展法则认为模型大小和数据大小应该以同等的比例增加 。
3.2 模型初始化
大模型训练是一个高度实验性的过程 ，需要承担较高的
试错成本 。过程中会涉及大量的超参数设置 ，包括权重初始
化、归一化方法 、激活函数 、位置嵌入 、学习率 、优化器
等。这里我们介绍一些常见的初始化设置 。
1） 权重初始化
合理的初始化权重可以帮助模型更快地收敛 ，使模型拥
有更好的性能 。最常见的就是高斯噪声初始化 。为解决深层
Transformer 收敛困难的问题 ，2019 年XU Q .[25]认为收敛困难
的原因是层归一化 （LN）和残差连接相互影响导致梯度消
失，提出了利普希茨约束参数初始化 （LRI）的参数归一化
方式 。与此同时 ，ZHANG B .[26]提出了一种参数初始化方式
DS-Init 。该方法通过在初始化阶段减少模型参数的方差 ，
来减少残差连接输出的方差 ，从而缓解反向传播过程中数据
通过正则化层时的梯度问题 。2020 年，HUANG X . S.[27]提出
了一种参数初始化策略 T-fixup 。该策略可以使模型参数在
没 有 预 热 （WarmUp ）和 层 归 一 化 的 情 况 下 仍 能 够 更 新
收敛 。
2） 归一化
训练不稳定是大模型面临的一个难题 。LN[28]被广泛应
用到 Transfromer 架构中 。LN的位置对于大模型的性能至关
重要 。2020 年，XIONG R .等提出了 Pre-LN[29]。相对于一般
Tranformer 中的 LN，研究人员将 LN这一阶段提前 ，解决了
学习率 WarmUp 阶段超参敏感问题 ，同时优化了收敛过程速
度慢等问题 ，但这也带来了一定的模型性能损失 。Chin ‐
chilla[24]则采用 RMS Norm[30]的方式 ，取消了传统 LN上的均值
计算 ，在训练速度和性能方面都具有优势 。
3） 激活函数
为了获得良好性能 ，前馈网络需要设置合适的激活函
数。现有大模型中 ，GeLU[31]被广泛使用 。此外 ，最新的大
模型如 PaLM 和LaMDA ，使用了 GeLU 的变体 SwiGLU[32]和
GeGLU[33]，取得了更好的性能 。
3.3 模型评估
在模型训练过程中 （或对于那些训练好的模型 ） ，我们
需要评估模型的能力 。通常会有很多基准数据集可用于评估
模型的逻辑推理 、翻译 、自然语言推理 、问答等方面的能
力。这里我们对常用评估方法及指标做一个介绍 。
1） 文本对比
一些常规的指标 ，比如 BLEU 、ROUGE 、METEOR 等，
23