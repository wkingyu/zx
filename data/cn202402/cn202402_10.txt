智能算力核心基础系统软件的现状与展望 郑纬民  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2的恢复机制 。该机制在训练过程中定期保存大模型的中间数
据，以便在发生错误或异常时能够快速恢复至上一个检查
点。然而 ，随着当前大模型参数量增大 （万亿级 ） ，训练所
需的集群规模随之扩增 （千卡至万卡 ） ，训练时间也更长
（数星期至数月 ） ，训练期间软硬件故障或异常出现的频次增
加，高成本的检查点读写开销将不足以支持大规模系统的有
效容错 。因此 ，一些研究工作尝试结合并行策略所引入的冗
余性 ，以降低检查点的读写成本 ，实现低成本容错 ，为用户
提供更加稳定和高效的训练环境 。
在国际上 ，大模型训练的容错技术得到不断地发展
和 完 善 ，诸 如 TensorFlow-Extended[12]、PyTorch （Torch ‐
Elastic ）[13]、Horovod[21]、Ray[40]等 典 型 人 工 智 能 训 练 框 架
均包含了针对分布式训练的容错机制 。这些框架大多采
用“监控器 +任务 ”的机制对模型训练任务进行监控调
度，以快速识别故障或异常的任务 ，并使用检查点恢复
的机制重启异常任务 。OpenAI 、Google 已经成功在配备成
千上万个 GPU 的集群上训练出 ChatGPT 、Gemini 、Sora 等
大模型 ，足以证明其在大模型训练的大规模分布式容错
方面具备丰富经验的 。
中国目前在大模型训练容错技术上也具备较为丰富的经
验。值得一提的是 ， “八卦炉 ”[41]训练框架支持在新一代国
产神威超算系统上 10万节点 （57万个核组 、3 700万核 ）的
大模型训练 ，该框架同样采用了基于检查点的恢复机制 。在
如此庞大规模系统上训练时 ，平均每 1 h就会出现一次故障 。
“八卦炉 ”采用分布式检查点技术将读写检查点的开销控制
在3 min 以内 ，实现了低成本的有效容错 。此外 ，字节跳动 、
快手 、商汤等公司各自研发的大模型训练框架中均实现了有
效的容错机制 。中国在大模型训练容错技术方面具备一定的
实力和竞争力 。
综上所述 ，大模型训练容错技术是大模型的关键系统软
件，可以提高大模型训练和推理过程的效率和可靠性 ，为人
工智能技术的发展和应用奠定更加稳定和可靠的基础 。目前
全球业界均具备在大规模系统上开展大模型训练的经验 ，大
多采取基于检查点的恢复机制进行容错 。随着大模型参数的
扩增 ，训练所需的系统规模随之增加 ，低成本的大模型容错
技术已逐渐成为一项重要的研究主题 。结合并行策略 、检查
点校验算法与硬件容错等方法或将成为降低容错成本的潜在
技术方案 。
4.3 内存分配系统
大模型的计算需要庞大而复杂的数据支持 ，这也同时直
接对应着硬件内存资源的需求 。内存分配因此面临着前所未有的挑战 。内存分配指的是在程序执行期间 ，动态地分配和
管理内存资源的过程 。这一过程旨在高效利用内存 ，避免资
源浪费 ，同时保证程序的高效运行 。内存管理策略通常包括
静态分配和动态分配 。静态分配在程序编译时完成 ，而动态
分配则允许程序在运行时根据需要分配内存 。例如 ，以
TensorFlow 为代表的框架 ，采用的就是静态分配策略 ，而以
PyTorch 为代表的一系列框架采用的是动态分配策略 。相比
较来说 ，静态分配效率高 ，但框架受限严重 ，不易用 ；动态
分配效率较低 ，但框架灵活 。当前最为主流的计算框架均基
于动态分配 。
大模型系统软件的内存分配面临多重挑战 。首先是数据
规模 ，大量的数据和模型 ，需要巨大的内存资源来处理 。通
常来说 ，硬件的内存资源决定了模型规模的上限 ，因此内存
资源的利用效率极为重要 ，也给内存分配带来了挑战 。其次
是性能 ，大模型训练需要非常频繁的申请与加速器上内存资
源的释放 。与此同时 ，加速器的直接内存的分配时间也各不
相同 。相比于 CPU 来说 ，加速器的直接内存需要更多的额
外时间 。因此 ，如何设计内存分配器 ，提高内存分配过程的
速度 ，尽量少地直接分配硬件内存资源 ，都给大模型应用带
来了巨大的挑战 。
为了应对这些挑战 ，研究人员针对大型模型应用开发了
一系列内存分配策略和优化技术 。通过利用内存池技术预先
分配内存块 ，有效减少了内存碎片和直接分配的时间开销 。
例如 ，清华大学的研究团队开发的 swAlloc[42]内存分配器 ，
专门针对神威芯片的特性和大模型应用需求 ，设计了特殊的
内存分配策略 。这一策略解决了在神威系统上内存分配效率
和速度的核心问题 ，为新一代神威超级计算机支撑的大规模
训练系统 “八卦炉 ”奠定了坚实的基础 。
此外 ，在涉及多台机器的大规模应用场景中 ，内存资源
的高效分配和利用显得尤为关键 ，同时也蕴含着巨大的优化
潜力 。特别是面对混合专家 （MoE）模型等复杂的新型模型
结构时 ，如DeepSpeed[17]所采用的 ZERO 优化器以及 “八卦
炉”[41]使用的 PARO 优化器 ，均在减少模型内存需求和提升
训练效率方面展示了能力 。在这种复杂环境下 ，进一步提高
内存资源的使用效率 ，成为了大模型系统研究中最为关键的
研究内容之一 。
大模型系统软件的内存分配是确保性能和效率的关键因
素。面对大模型系统软件在规模和性能等方面存在的挑战 ，
设计研究合适的内存分配策略和优化技术至关重要 。
4.4 存储系统
在大模型训练中 ，存储系统不仅可以保存数据 ，而且在
06