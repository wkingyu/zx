大模型训练技术综述 田海东  等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2可用来衡量文本的重叠度 。PYRAMID[34]可以衡量语义重叠
度。对于代码生成模型 ，pass@k[35]是一个重要衡量指标 。对
于多输出的复杂模型 ，KoLA[36]将大模型的评价和认知层面
联系起来 。KoLA 的评测任务由认知层级决定 。认知层级包
括知识记忆 （KM） 、知识理解 （KU） 、知识应用 （KA） 、知
识创造 （KC） 。
当然 ，我们也可以从其他方面来评估模型 ，比如 ：鲁棒
性（NL-Augmenter[37]的语义不变扰动 ） 、基于计数的性别和
种族 bias[38]、不确定性及公平性等 。
2） 自动评估和人类评估
自动评估是指利用一些小模型对大模型的结果进行评
估，例如毒性评估相关 （ML-based Perspective[39]） 、对话系
统等 。
此外 ，我们也可以使用单纯的人类评估 。人类评估是自
然语言处理领域中衡量模型或算法性能的关键方法 。然而 ，
人类评估存在不稳定 、可重复性低等问题 ，这可能导致评估
结果不够准确 。HUSE[40]尝试模仿人类评估的方法 ，并将人
类评估和统计评估相结合 ，实现多样性评估 。
4 训练并行及网络
随着深度学习模型参数和数据规模的增长 ，传统的单机
单卡模式已无法满足大模型的训练要求 。因此 ，我们需要基
于单机多卡 、多机多卡进行大模型的分布式训练 。而利用计
算集群 ，从大量数据中高效地训练出性能优良的大模型是分
布式训练的首要目标 。为了实现该目标 ，需要根据硬件资源
与数据模型规模的匹配情况 ，来对计算任务 、训练数据和模
型进行划分 ，从而实现分布式训练并行 。
4.1 常见的并行策略
这里我们介绍几种常见的并行策略 ，即数据并行 、张量
并行和流水线并行 。在大模型训练的过程中 ，通常会将上述
并行策略进行组合使用 ，即混合并行 。
1） 数据并行
数据并行是提高训练吞吐量的基本方法之一 。它将模型
参数和优化器状态复制到多个 GPU 上，然后将整个训练语
料库分配到这些 GPU 上。这样 ，每个 GPU 只需要处理分配
给自己的数据 ，并执行前向和反向传播以获取梯度 。在不同
GPU 上计算出的梯度将进一步聚合以获得整个批量的梯度 ，
然后更新所有 GPU 上的模型 。由于不同 GPU 上的梯度计算
是独立进行的 ，数据并行机制具有高度可扩展性 ，因此可以
通过增加 GPU 数量来提高训练吞吐量 。以PyTorch 为例 ，数
据并行方式有 ：数据并行 （DP） 、分布式数据并行 （DDP） 、完全分片数据并行 （FSDP ）等。
2） 张量并行
张量并行专注于分解大模型的张量 ，将一个张量沿着特
定维度分成 N块。每个 GPU 保持整个张量的 1/N，同时不影
响整个计算图的正确性 。张量并行可以通过跨 GPU 通信将
多个 GPU 的输出结果聚合成最终结果 。最早的张量并行方
案由 Megatron-LM[41]提出 ，它是一种高效的一维张量并行实
现方法 。为了平均分配计算和内存负荷 ，Colossal-AI[42]把张
量沿着两个维度进行切分 ，这就是二维张量并行 。除此之
外，Colossal-AI 还可以支持更高维度的张量并行 。
3） 流水线并行
流水线并行是指将大模型的不同层分配到不同的 GPU
上，以降低单个 GPU 的显存消耗 。然而 ，传统流水线并行
方 式 的 GPU 空 泡 率 较 高 。针 对 该 问 题 ，Gpipe[43]提 出 了
micro-batch 的方式以减少空泡率 。PipeDream[44]在Gpipe 的基
础上使用 1F1B的方式优化流水线并行策略 ，以减少流水的
空闲时间和显存 。在后续的一些研究中 ，PipeDream- 2BW和
PipeDream-Flush[45]等基于原始的 PipeDream 做了进一步的
改进 。
4） 序列并行
序列并行是指将序列这个维度划分到不同的 GPU 上进
行并行计算 。例如 LI S.[46]为解决大模型输入序列长度的限
制，将输入序列分割到多个 GPU 上，并提出环自注意力 ，
将环状通信与自注意力相结合 ，可以处理超过 1.14×105的
长度序列 。
同样地 ，Megatron-LM[41]在进行张量并行的时候 ，将
LayerNorm 和Dropout 的输入按长度进行了划分 ，使得各 GPU
只需要完成一部分 Dropout 和LayerNorm 操作 ，并使用选择性
激活重计算以减少激活显存 。
4.2 其他并行优化策略
1） 基于显存的优化技术 ZeRO
ZeRO[47]是由 DeepSpeed 提出的在数据并行过程中降低显
存的一种技术 。该技术可以使得单个 GPU 的显存占用随着
GPU 的数量增加而线性下降 。ZeRO 一共提供了 3种解决方
案：优化器分区 、梯度分区和参数分区 。前2种方案不会带
来新的通信开销 ，第3种方案会增加 50%的通信开销 。与此
同时 ，ZeRO 提供 ZeRO-R 在数据并行节点间划分激活 ，来
减少激活的显存开销 。
2） 基于模型结构的并行
混合专家 （MoE）模型是一种基于模型结构的并行架
构。它将大模型拆分成多个小模型 （专家模型 ） ，在每一轮
24