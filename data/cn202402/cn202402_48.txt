低资源集群中的大语言模型分布式推理技术 冯文佼   等 热点专题
中兴通讯技术
2024  年 4 月    第 30 卷第  2 期   Apr . 2024    Vol . 30  No. 2在低资源条件下进行 LLM 推理仍存在一些不足 。1）单张计
算卡在算力和显存容量上面临明显限制 。例如 ，NVIDIA 的
A100和H100这类图形处理器 （GPU） ，在FP16运算性能上
比中国的寒武纪思元 、燧原邃思领先逾 7倍，显存容量超 5
倍。对于中国的 LLM 推理应用来说 ，计算效率和存储能力
成为了明显的瓶颈 。2）多主机间的通信带宽远小于主机内
的高速网络带宽 。较大的模型不适合单张计算卡 ，需要依赖
多卡服务器集群以适应显存 。这也使我们能够将上述的计算
成本和显存分摊到所有计算卡上 ，但代价是引入计算卡间通
信。而在中低端数据中心内 ，主机间的网络带宽普遍限制在
1~25 Gbit/s ，与主机内可达 100 Gbit/s 的显存带宽和互联带宽
相距甚远 。这使得多机间互联网络的通信效率成为制约分布
式推理性能的主要瓶颈 。
此外 ，当前 LLM 主要采用 Transformer 架构[4]。它的主要
思想是通过自注意力机制获取序列的全局信息 ，并将这些信
息 通 过 网 络 层 进 行 传 递 。区 别 于 传 统 的 卷 积 神 经 网 络
（CNN）和循环神经网络 （RNN） ，Transformer 架构由于具有
多个独立的注意力头 ，因此不需要按照时间步骤进行计算 ，
具有更强的并行计算能力 。为了实现最佳的性能和资源利用
率，现在很多研究致力于自动混合并行推理 ，包括 AlpaS ‐
erve[5]、FlexFlow-Serve[6]和SpotServe[7]等。这些框架能够将自
动搜索算法应用于 LLM 的推理过程 ，以确定最有效的并行
策略 。然而 ，分布式推理面临的主要挑战之一是数据通信产
生了额外负担 ，因为这可能增加总体推理响应时间 。尽管现
有策略优化了并行计算 ，但它们往往忽略了针对 Transformer
架构特有通信需求的优化 ，这可能导致在推理过程中出现更
加明显的延迟 。
考虑到 Transformer 架构固有的内存密集型特性 ，高效的
显存管理仍然是 LLM 分布式推理中面临的首要挑战 。ZeRO-
Offload[8]和ZeRO-Infinity[9]支持内存卸载 ，将GPU 的显存压
力分担到 CPU 甚至 NVMe 内存上 ，从而打破 GPU 的显存限
制。但此类方法需要所有计算卡间拥有高速连接 ，因此使用
场景将会受到很大的限制 。
针对上述挑战 ，本文提出了适用于低资源集群的 LLM
分布式推理技术 ，实现用数量有限的低资源设备 ，最大化能
推理的 LLM ，同时通过优化通信策略与计算调度来加速
推理 。
1 问题与动机分析
由于 LLM 推理对设备算力和显存容量有较高要求 ，
Megatron-LM[10]通过张量并行将模型层 ，例如注意力 、全连
接前馈网络 （FFN） ，从内部维度 （例如头部 、隐藏层 ）分割成多个部分 ，并将每个层部署在单独的计算卡上 。但这种
朴素的张量并行存在一个问题 ：自注意力的输出必须通过
LayerNorm 才能输入到 FFN 中进行计算 。LayerNorm 的正确性
依赖于所有计算卡的自注意力结果 ，这是因为单卡结果无法
确保其准确性 。为此 ，Megatron-LM 提出 Reduce+Layer ‐
Norm+Broadcast 算子 ，即计算卡完成自注意力输出后 ，先聚
合（Reduce ）到 一 卡 执 行 LayerNorm ，再 将 结 果 广 播
（Broadcast ）回各卡继续多层感知机 （MLP）计算 。虽然该
算子解决了 LayerNorm 层的并行问题 ，但它仍依赖单卡执行
Reduce 、LayerNorm 及Broadcast 。一方面 ，这种中心化的计
算与通信算子会遭遇单点瓶颈 ；另一方面 ，这种算子的适用
通信原语局限于 Reduce 和Broadcast ，与诸多经典的 All-
Reduce 通信库及其高效的 All-Reduce 原语实现 （如Ring 、
Three-Phase Ring 等）均不兼容 。
由于典型数据中心的分层网络结构限制了跨主机带宽 ，
All-Reduce 的性能也会受阻 。大规模 LLM 推理需要多主机合
作以满足算力和显存要求 。尽管单机多卡间可通过 NVLink
和高速串行计算机扩展总线标准 （PCIe）实现高速通信 ，但
各主机通常按机架分组并连接至架顶式 （ToR）交换机 。其
中，机架内各主机通过 1~25 Gbit/s 的完整链路平分带宽进行
互联 ，这限制了多主机间 All-Reduce 的通信效率 。相关研究
集中于优化模型训练阶段的 All-Reduce 通信 ，通过探测网络
结构并制定分层聚合策略以适应网络变化 ，从而解决长期通
信不平衡问题 ，但这并不完全适用于推理阶段 。与训练不
同，推理尤其是在线推理的持续时间较短 ，其核心目标是实
现低延迟和高吞吐 。因此 ，推理阶段更需针对带宽差异引致
的通信瓶颈进行优化 。
此外 ，为了实现用数量有限的低资源设备最大化能推理
的LLM ，同时考虑到 Transformer 架构固有内存密集性 ，高效
的显存管理仍然是 LLM 分布式推理中面临的首要挑战 。现
有推理系统[3-11]基于高性能智算中心开发了一系列内存卸载
技术 ，例如 ：通过频繁通信实现了 GPU 显存负载转移至
CPU 或NVMe 存储 ，有效突破显存限制 。然而 ，这些推理系
统往往沿用了为训练阶段设计的卸载技术[8-9,12-14]，直接应用
于资源受限的分布式推理可能不理想 。因为这些技术在资源
受限环境下可能导致对更多计算卡和高并行度的依赖 ，增加
通信复杂性 ，并且主机间的低带宽难以支持这种强度的通
信。同时 ，这些技术忽略了生成推理的特殊计算属性 ，未能
利用面向吞吐量的 LLM 推理计算的结构 ，并错过了有效调
度输入输出 （I/O）流量的绝佳机会 。这些先前的工作促使
我们设计一套适用于低资源集群的 LLM 分布式推理技术方
案。该方案引入了一种高兼容的分布式推理范式 ，同时特别
44