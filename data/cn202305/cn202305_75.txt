NetGPT ：超越个性化生成服务的内生智能网络架构 陈宇轩  等 热点专题
中兴通讯技术
2023  年 10 月    第 29 卷第  5 期   Oct . 2023    Vol . 29  No. 5码，自然地将显式相对位置依赖性纳入自注意力公式中 。相
较于给序列中每个位置分配独特编码表示的句对位置编码方
式，RoPE 中所采用的相对位置编码方式能更有效地对上下
文信息中的远程依赖关系进行建模 ，易于直观理解 ，并且在
实验中表现出优秀的性能 。
1.3 微调技术
1.3.1 基于低秩自适应的轻量级微调
LLaMA 缺乏生成响应式文本的能力[7]，因此仍需进行微
调，但直接微调会耗费大量的计算资源 。例如 ，直接微调
LLaMA- 7B模型需要 112 GB视频随机存取存储器 （VRAM ） ，
这超过 NVIDIA A 100 Tensor Core GPU 的容量 。因此 ，我们
采用低秩适应 （LoRA ）技术[11]在消费级硬件上进行参数高
效的微调 。为了微调完整的参数矩阵 W∈Rdin×dout，LoRA 添
加了一条旁路路径 ，通过使用两个具有内在秩 r的下游参数
矩阵A∈Rdin×r和B∈Rr×dout来模拟矩阵更新 ΔW。也就是说 ，
在r ≪ min(din, dout)的条件下 ，LoRA 成功地将大型参数矩阵
ΔW转换为 ΔW ≈ AB的低秩矩阵 。实验证明 ，微调后的
LLaMA- 7B模型只消耗了 28 GB VRAM 而没有明显增加训练
时间 。另外 ，微调后需要的存储空间由 12.55 GB明显缩小至
50 MB左右1。基于 LoRA ，我们使用 Stanford Alpaca 数据集[12]
对LLaMA- 7B模型进行微调 ，成功得到响应式 LLaMA- 7B
模型 。1.3.2 在LLM 引导下收集数据
为了实现个性化边缘 LLM ，GPT- 2-base 模型需要通过
附加基于位置的额外信息对 “简明提示 ”进行扩展 。本质
上，基于 5G接入与移动管理功能 （AMF）所储存的附属 BS
位置能够很容易得到定位信息 。同时 ，为了补充更全面的信
息，本文中我们用 self-instruct 方法[13]，即使用 OpenAI 的
TextDavinci- 003模型来生成有效的文本样本 。在每个地区 ，
我们使用一组手动编写的位置相关提示与 OpenAI 的Text‐
Davinci- 003模型进行交互 ，并将生成响应文本作为 “综合
提示 ” 。与此相对应 ，可以收集一系列 “简明提示 ”和“综
合提示 ”之间的映射关系 。考虑到边缘 LLM 的规模和任务
复杂性 ，我们收集了一个包含大约 4 000个样本的数据集 ，
将GPT- 2的模型微调为即时完成模型 。值得注意的是 ，针
对高通用性的场景 ，可以使用更大规模的 LLM 来增强边缘
LLM ，也可以采用 LoRA 等微调技术 。
1.4 性能展示
图3显示的是 NetGPT 的性能 。其中 ，边缘 LLM 能够根
据左侧的图表补充 “简明提示 ” ，从而产生每一个对应的
“综合提示 ” 。不同基站也加入基于位置的个性化信息来满足
不同需求 。随后 ，边缘 LLM 对用户提出的 “简明提示 ”进
行处理 ，并向云端反馈补充提示信息 ，之后云端 LLM 再给
出完整的回应 。从图 3右侧可看出 ，NetGPT 能产生基于位置
的不同回应 ，这反映出通过对云边进行高效的协同处理可以
实现个性化的服务生成 。
1 此类统计数据是在 r = 8且与学习率相关的标量因子等于 16的配置下获得的 。
图 3 NetGPT 基于位置的个性化生成服务的性能展示地区 Brooklyn 地区 Manhattan
71