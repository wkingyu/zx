中兴通讯技术
2023  年 6 月    第 29 卷第  3 期   Jun . 2023    Vol . 29  No. 3基于长短期记忆网络的数字孪生移动通信网络环境生成技术 梁广明  等 热点专题
2 数字孪生环境生成技术
2.1 长短期记忆网络
时间序列预测的基础是 ，当前时隙的数据与过去时隙的
数据存在着时间相关性 。通信网络中的时序数据往往都存在
着较为复杂的非线性关系 ，因此适合采用数据驱动的 LSTM
方法[10]来挖掘当中的时序相关性 ，解决时间序列预测的
问题 。
LSTM 是递归神经网络 （RNN）[11]的变种 ，它解决了
RNN 无法学习时序数据中 ，当前时隙数据与过去较远时隙
数据之间的长期相关性的问题 。RNN 较为简单的循环结构 ，
导致过去较远时刻产生的梯度在当前时刻会出现消失现象 ，
因此无法有效学习到数据间的长期依赖关系 。相比 RNN 只
有一个传递状态 ，LSTM 有两个传输状态 ，分别是细胞状态
ct和隐藏状态 ht。细胞状态 ct在传递过程中变化很慢 ，通常
是由上一个状态传递过来的 ct-1经过少量线性变换得到的 ，
而隐藏状态 ht则在传递过程中发生较快变化 。
LSTM 内部结构如图 2所示 。其中 ，zf、zi和zo是门控状
态，相应的生成过程如下 ：当前状态输入 xt和上一状态传递
下来的 ht-1拼接形成向量 st；向量st乘以不同的权重矩阵 ，
并通过 sigmoid 激活函数转换为 0到1之间的数值 。而图 2中z
是输入数据 ，相应的生成过程如下 ：拼接向量 st乘以相应的
权重矩阵后 ，通过 tanh 激活函数转换到 -1到1之间的数值 。
门控状态 zf、zi和zo以及输入数据 z对应的计算公式为 ：
zf=sigmoid(Wfst)， （1）
zi=sigmoid(Wist)， （2）
zo=sigmoid(Wost)， （3）
z=tanh(Wst)， （4）
其中 ，Wf、Wi、Wo和W分别是 zf、zi、zo和z对应的权重
矩阵 。
在LSTM 内部向量的计算中 ，⊙
代表哈达玛乘积 ，即两个矩阵中对应
的元素相乘 ，而⊕代表的是矩阵加法 ，
即两个矩阵中对应的元素相加 。LSTM
其余变量计算公式为 ：
ct=zf⊙ct-1+zi⊙z， （5）
ht=zo⊙tanh (ct)， （6）
yt=sigmoid(W'ht)， （7）其中 ，yt为当前状态输出值 ，W'为yt对应的权重矩阵 。
LSTM 内部主要有 3个阶段 ，分别是遗忘阶段 、选择记
忆阶段和输出阶段 ：
1）遗忘阶段 。该阶段是对上一个状态输入的 ct-1信息
进行选择性遗忘 ，即采用 zf作为遗忘门控 ，以控制哪些数值
需要遗忘 。
2）选择记忆阶段 。该阶段对当前状态输入的 xt和ht信
息进行选择性记忆 ，即采用 zi作为选择记忆门控 ，以控制哪
些数值需要被着重记忆 。
3）输出阶段 。该阶段将决定哪些经过变换后的输入信
息将会被当成当前状态的输出 ，即采用 zo作为输出门控 ，以
控制整个输出过程 。与RNN 类似 ，yt是通过 ht进行变换得
到的 。
如图 3所示 ，将LSTM 按状态进行展开时 ，每个状态的
细胞状态和隐藏状态信息都会被刷新并向下一个状态传输 ，
而权重矩阵 Wf、Wi、Wo、W和W'都是固定的 。训练时 ，需
要采用反向传播算法[12]优化上述 5个权重矩阵 。训练完成
后，选择性能表现最好的矩阵参数 ，执行前向传播算法 ，并
输出预测结果 。这种方法的总体思想是 ，通过 LSTM 中的细
胞状态和隐藏状态提取时间特征之后 ，将时序特征送入全连
图2 长短期记忆网络的内部结构图
图3 LSTM 状态展开图LSTM ：长短期记忆网络ct-1ctyt
ht
z fz iz z otanh
ht-1xt
LSTM LSTM LSTM
…… ……yt-1
ct-1
ht-1
xt-1xtxt+1ytyt+1
ct
htct+1
ht+1ct+2
ht+2
17