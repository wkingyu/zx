专  题 智能算力
20中兴通讯服务器及存储
产品总工周赞鑫
中兴通讯系列化智算服务器方案，
助力数字经济蓬勃发展
人计算性能和效率。
大容量内存：具有足够容量的内存可以加速
数据流和算法处理速度。
高带宽网络接口：需要高速网络带宽
（100Gbps及以上），以便在训练过程中传
输大量数据。
AI大模型的兴起对智算服务器提出了更高的
要求，特别是大模型训练计算量巨大，单个GPU
无法满足训练算力需求，需要使用单机多卡或多
机集群实现TP/DP/PP等并行训练。大模型对智算
服务器的特殊要求体现在以下几个方面：
高性能&大显存GPU：大模型需要大量的并
行计算能力，且需要存储大量的参数和梯度
信息，因此需要高性能&大显存GPU来进行
训练和推理。
机内GPU 高速互联：单机多卡TP 并行对智算
服务器的多个 GPU之间通信带宽有极高的要
求，需要使用支持高速互联通道的扣卡型
GPU加速卡，实现机内8 卡高速互联，以加
速数据传输和模型同步。
机间高性能互联网络：采用多机集群时，为
了充分发挥 GPU集群计算资源的强大算力，
机间参数面互联网络需采用高速多轨道流量
聚合架构。一方面，要求 PCIe5.0插槽以便
使用200/400G高性能、低延迟的IB/RoCE网
卡；另一方面，要求至少10个以上网卡插
槽，管存面至少2 个网卡，GPU 和参数面网
卡按照8 :8配比，以实现多台智算服务器间
相同位置GPU卡所连参数面网卡都归属于同
一交换机，优化通信效率，加速并行传输。工智能（AI）领域正迎来新一轮快
速发展，生成式AI对算力的需求迅
速增加，这将成为AI计算市场新的增
长点和加速器。
中国智算服务器市场
2023年中国智算服务器保持了快速增长。据
IDC2023H1数据统计，2023年加速服务器预计发
货规模达31.6万台，同比增长 11.3%；营收约89.9
亿美元，同比增长79.7%；其中GPU加速服务器
（智算服务器）占比约90%。 IDC预测，2027年
加速服务器营收将加速增长，达164亿美元；发
货规模将达到69.1万台。
目前，单机配置8 或4张GPU加速卡的智算服
务器是客户的主流选择，其中Nvidia GPU加速卡依
然是市场主流，份额高达90%左右。此外，面向推
理方向应用的智算服务器份额约占60%左右。
AI应用对智算服务器的要求
智算服务器相比通用服务器主要有以下特点：
高性能CPU： AI训练和推理需要大量的计算
资源，需要配备高性能CPU，以满足大数据
集的处理需求。
GPU加速卡：GPU可以提供比CPU更高效的
并行计算，从而加速深度学习模型的训练和
推理，插卡型 GPU加速卡可以满足大部分中
小模型训练&推理应用需求，单台服务器支
持4~8张 GPU加速卡实现并行处理，可提升