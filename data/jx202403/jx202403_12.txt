图2  智算中心层次化部署
       模式
10
视  点
场景：基础大模型预训练
特点：4+N集中化部署，超大规模GPU集群
关键挑战：
提升大规模集群算效及能效，提升训练可靠性集中新建
场景：大模型精调/推理/应用
特点：分布式按需扩展，多样化算力应用
关键挑战：
提升多样化资源管理效率和资源利用率，
开放解耦能力和应用生态通用DC升级
场景：企业私域数据精调/推理/应用
特点：边缘按需部署，训推一体
关键挑战：
实现政企客户入驻场景快速部署，提供智算
一体化服务一体机入驻
通算 训练 推理
x86/ZF NV/BR/CAM等 NV/BR/CAM等统一云平台，算力原生
边缘训推
一体机
边缘训推
一体机边缘训推
一体机集中训练
模型更新和数据采集
场景一：大模型训练 场景二：训推混合 场景三：边缘训推
成到此类环境中。此外，Slurm使用较为复杂，
维护难度大；另一方面，Kubernetes更易于使
用，并与常见的机器学习框架集成，越来越多的
企业和学术机构在他们的大模型训练中使用 
Kubernetes。但是使用Kubernetes调度GPU资源
时会遇到资源闲置时间过长，导致的集群平均利
用率低（约为20%）、资源调度只能整卡调度，
不能切分或按照卡的类型调度、不能进行任务排
队等问题。
部署场景
由于基础大模型预训练、行业大模型精调以
及客户场景大模型微调对算力特征及部署位置的
要求均不同，结合运营商算力网络DC层次化分布
的架构，智算中心部署也呈现枢纽大模型训练中
心、省份训推融合资源池、边缘训推一体机三级
部署模式（见图 2）。
当前，智算已经成为国家竞争的关键技术方
向，运营商肩负着提升智算关键软硬件技术创新
能力及智算基础设施建设的使命。中兴通讯拥有
从IDC、芯片、服务器、存储、数通等基础设施
到资源管理平台的全系列产品，结合在电信、政
企领域的丰富经验，将助力运营商在智算技术创
新及建设中大展宏图。换机，构成一个轨道平面。同时，服务器不同位
置GPU连接到不同交换机，形成多个轨道平面。
资源任务调度平台
和通用算力资源管理平台通过虚拟云化技术
将资源分发给多个租户不同，智算场景更强调的
是算力聚合，即在AI 任务训练中，可能同时运行
数百个任务和上千个节点。通过任务调度平台，
可以将执行的任务与可用资源进行最佳匹配，从
而最小化任务在队列中等待的时间长度，最大化
任务并行量，获得最优资源利用率。目前主流的
调度系统有Slurm、 Kubernetes两种。
Slurm主要应用于HPC场景下的任务调度，
已经被世界范围内的超级计算机（包括天河等）
和计算机群广泛采用；而Kubernetes作为容器编
排平台，用于调度以及自动部署、管理和扩展容
器化应用。目前Kubernetes和更广泛的容器生态
系统逐渐成熟，正在形成一个通用的计算平台和
生态系统。
在AI任务调度场景下，Slurm和 Kubernetes
面对着不同的挑战：深度学习工作负载的特征与
HPC工作负载的特征非常相似，因此可以使用
HPC任务调度器Slurm来管理其机器学习集群。
但是，Slurm不是围绕容器开发的机器学习生态
系统的一部分，因此很难将Kube/f_low等 AI平台集