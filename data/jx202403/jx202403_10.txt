图1  智算中心创新架构
08
中兴通讯云计算规划总工朱堃智能算力
发展趋势洞察
视  点
算力
存储 网络基础设施
CPU 块存储 普通网络
配套设施
小功率机架 风冷散热资源管理
云化资源（虚机/容器/裸金属）编排（新型）智算中心 通算中心
资源管理
任务编排 集群调度 能力增强
基础设施
CPU/xPU 多元存储 无损网络
配套设施
大功率机架 风/液冷散热
无损/低时延矩阵运算/并行处理/集群计算
并发访问/海量多模态小功率/风冷   大功率/液冷 CPU  xPU 云计算资源调度  集群管理/任务调度随AI芯片
除了大模型训推有高性能矩阵运算的要求之
外，大模型参数量越大对内存容量的需求越大，同
时多颗AI芯片间的大量数据交互也带来了对互联总
线高带宽、低时延的要求。因此，算力、显存，以
及互联总线形成了对AI芯片的三大能力要求。
算力方面，由于人工智能采用基于多层神经
网络的机器学习技术，需要对大量数据进行矩阵
运算，例如矩阵乘法、卷积、激活函数等。传统
CPU以复杂数据流程见长，为此将更多的空间让
渡给了控制单元和缓存单元，计算单元只占 25%
的空间，一般只有几十个算术逻辑单元
（ALU），处理这些并行化和向量化运算的效率
不高。而处理图像和图形相关运算的GPU计算单
元占90% 的空间，高达几千的ALU 适合对密集数
据进行并行处理。在2017年后，主流AI芯片厂家
发布专门针对矩阵运算加速的AI GPU（ GPGPU，
general purpose computing on GPU），为大模
型训练提供了更高的计算性能。除硬件之外，
GPU厂家通常会提供相应的开发平台（如NVIDIA 
CUDA），它使得开发者能够直接使用GPU进行
编程和优化，充分发挥GPU的计算能力。
显存方面，Transformer类模型参数量按照着ChatGPT 横空出世，人工智能
（AI）技术在短时间内呈现“涌
现”态势，并成为推动社会进步的
关键力量。AI 技术的广泛应用给我们的生活和工
作带来了巨大的改变，而这一切的背后离不开算
力基础设施的支持。AI 训练任务以及推理应用对
算力有着高性能、大规模并行、低时延互联的要
求，导致对计算、存储、互联网络有了不同于通
用计算的要求，同时对算力聚合的要求也引发了
基础设施管理平台的创新（见图 1）。